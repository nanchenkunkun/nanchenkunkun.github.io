<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/nanchenkunkun.github.io/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/nanchenkunkun.github.io/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/nanchenkunkun.github.io/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/nanchenkunkun.github.io/images/logo.svg" color="#222">

<link rel="stylesheet" href="/nanchenkunkun.github.io/css/main.css">


<link rel="stylesheet" href="/nanchenkunkun.github.io/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"nanchenkunkun.github.io","root":"/nanchenkunkun.github.io/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="只有变光,才能变强">
<meta property="og:type" content="website">
<meta property="og:title" content="kkの博客">
<meta property="og:url" content="https://nanchenkunkun.github.io/index.html">
<meta property="og:site_name" content="kkの博客">
<meta property="og:description" content="只有变光,才能变强">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="zkk">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://nanchenkunkun.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>kkの博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/nanchenkunkun.github.io/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">kkの博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">南城坤坤</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/nanchenkunkun.github.io/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/nanchenkunkun.github.io/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">5</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/nanchenkunkun.github.io/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">9</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/nanchenkunkun.github.io/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">33</span></a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://nanchenkunkun.github.io/2020/09/16/java/%E6%A1%86%E6%9E%B6/mybatis/mybatis%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/nanchenkunkun.github.io/images/1.jpg">
      <meta itemprop="name" content="zkk">
      <meta itemprop="description" content="只有变光,才能变强">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kkの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/nanchenkunkun.github.io/2020/09/16/java/%E6%A1%86%E6%9E%B6/mybatis/mybatis%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" class="post-title-link" itemprop="url">mybatis源码分析</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-09-16 13:52:18 / 修改时间：17:32:40" itemprop="dateCreated datePublished" datetime="2020-09-16T13:52:18+08:00">2020-09-16</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/java/" itemprop="url" rel="index"><span itemprop="name">java</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/java/%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">框架</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/java/%E6%A1%86%E6%9E%B6/mybatis/" itemprop="url" rel="index"><span itemprop="name">mybatis</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="从-XML-中构建-SqlSessionFactory"><a href="#从-XML-中构建-SqlSessionFactory" class="headerlink" title="从 XML 中构建 SqlSessionFactory"></a>从 XML 中构建 SqlSessionFactory</h3><p>每个基于 MyBatis 的应用都是以一个 SqlSessionFactory 的实例为核心的。SqlSessionFactory 的实例可以通过 SqlSessionFactoryBuilder 获得。而 SqlSessionFactoryBuilder 则可以从 XML 配置文件或一个预先配置的 Configuration 实例来构建出 SqlSessionFactory 实例。</p>
<p>从 XML 文件中构建 SqlSessionFactory 的实例非常简单，建议使用类路径下的资源文件进行配置。 但也可以使用任意的输入流（InputStream）实例，比如用文件路径字符串或 file:// URL 构造的输入流。MyBatis 包含一个名叫 Resources 的工具类，它包含一些实用方法，使得从类路径或其它位置加载资源文件更加容易。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">String resource = <span class="string">&quot;org/mybatis/example/mybatis-config.xml&quot;</span>;</span><br><span class="line">InputStream inputStream = Resources.getResourceAsStream(resource);</span><br><span class="line">SqlSessionFactory sqlSessionFactory = <span class="keyword">new</span> SqlSessionFactoryBuilder().build(inputStream);</span><br></pre></td></tr></table></figure>

<p>XML 配置文件中包含了对 MyBatis 系统的核心设置，包括获取数据库连接实例的数据源（DataSource）以及决定事务作用域和控制方式的事务管理器（TransactionManager）。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">configuration</span></span></span><br><span class="line"><span class="meta">  <span class="meta-keyword">PUBLIC</span> <span class="meta-string">&quot;-//mybatis.org//DTD Config 3.0//EN&quot;</span></span></span><br><span class="line"><span class="meta">  <span class="meta-string">&quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">environments</span> <span class="attr">default</span>=<span class="string">&quot;development&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">environment</span> <span class="attr">id</span>=<span class="string">&quot;development&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">transactionManager</span> <span class="attr">type</span>=<span class="string">&quot;JDBC&quot;</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">dataSource</span> <span class="attr">type</span>=<span class="string">&quot;POOLED&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;driver&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;driver&#125;&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;url&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;url&#125;&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;username&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;username&#125;&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;password&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;password&#125;&quot;</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">dataSource</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">environment</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">environments</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">mappers</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mapper</span> <span class="attr">resource</span>=<span class="string">&quot;org/mybatis/example/BlogMapper.xml&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">mappers</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">//构建了sqlsessoinfactory之后就可以获取 sqlsession</span></span><br><span class="line"><span class="keyword">try</span> (SqlSession session = sqlSessionFactory.openSession()) &#123;</span><br><span class="line">  Blog blog = (Blog) session.selectOne(<span class="string">&quot;org.mybatis.example.BlogMapper.selectBlog&quot;</span>, <span class="number">101</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//这个是用来生成SqlSessionFactory工厂的方法</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> SqlSessionFactory <span class="title">build</span><span class="params">(Reader reader)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.build((Reader)reader, (String)<span class="keyword">null</span>, (Properties)<span class="keyword">null</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> SqlSessionFactory <span class="title">build</span><span class="params">(Reader reader, String environment, Properties properties)</span> </span>&#123;</span><br><span class="line">        SqlSessionFactory var5;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//解析xml</span></span><br><span class="line">            XMLConfigBuilder parser = <span class="keyword">new</span> XMLConfigBuilder(reader, environment, properties);</span><br><span class="line">            var5 = <span class="keyword">this</span>.build(parser.parse());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception var14) &#123;</span><br><span class="line">            <span class="keyword">throw</span> ExceptionFactory.wrapException(<span class="string">&quot;Error building SqlSession.&quot;</span>, var14);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            ErrorContext.instance().reset();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                reader.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException var13) &#123;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> var5;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>XMLConfigBuilder类</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">四个属性:</span><br><span class="line">  private boolean parsed;</span><br><span class="line">  private final XPathParser parser;</span><br><span class="line">  private String environment;</span><br><span class="line">  private final ReflectorFactory localReflectorFactory;</span><br><span class="line">  </span><br><span class="line">七个构造方法：</span><br><span class="line">  public XMLConfigBuilder(Reader reader)</span><br><span class="line">  public XMLConfigBuilder(Reader reader, String environment)</span><br><span class="line">  public XMLConfigBuilder(Reader reader, String environment, Properties props) </span><br><span class="line">  public XMLConfigBuilder(InputStream inputStream) </span><br><span class="line">  public XMLConfigBuilder(InputStream inputStream, String environment)</span><br><span class="line">  public XMLConfigBuilder(InputStream inputStream, String environment, Properties props) </span><br><span class="line">  private XMLConfigBuilder(XPathParser parser, String environment, Properties props)</span><br><span class="line"> </span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//上一步所调用的是这个构造函数</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">XMLConfigBuilder</span><span class="params">(Reader reader, String environment, Properties props)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>(<span class="keyword">new</span> XPathParser(reader, <span class="keyword">true</span>, props, <span class="keyword">new</span> XMLMapperEntityResolver()), environment, props);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>​    </p>
<p>XPathParser类</p>
<p>My Batis 提供的XPathParser 类封装了前面涉及的XPath 、Doc ument 和EntityResolver </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">private Document document ; &#x2F;&#x2F; D ocu me nt 对象</span><br><span class="line">private boolean validation; ／／是否开启验证</span><br><span class="line">private EntityResolver entityResolver ; ／／ 用于加载本地D T D 文件</span><br><span class="line">private Properties variables ; &#x2F;&#x2F; mybatis -c onfi g. xml 中＜ p ropter i es ＞ 标签定义的键位对集合</span><br><span class="line">private XPath xpath ; &#x2F;&#x2F; XPath 对象</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E7%A9%BF%E9%80%8F%E3%80%81%E5%87%BB%E7%A9%BF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/nanchenkunkun.github.io/images/1.jpg">
      <meta itemprop="name" content="zkk">
      <meta itemprop="description" content="只有变光,才能变强">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kkの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E7%A9%BF%E9%80%8F%E3%80%81%E5%87%BB%E7%A9%BF/" class="post-title-link" itemprop="url">reids雪崩、穿透、击穿</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-09-08 11:28:53 / 修改时间：11:34:33" itemprop="dateCreated datePublished" datetime="2020-09-08T11:28:53+08:00">2020-09-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">中间件</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/" itemprop="url" rel="index"><span itemprop="name">redis</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Redis雪崩"><a href="#Redis雪崩" class="headerlink" title="Redis雪崩"></a>Redis雪崩</h3><p>大量key同一时间点失效，同时又有大量请求打进来，导致流量直接打在DB上，造成DB不可用。</p>
<p>解决方案：</p>
<p>处理缓存雪崩简单，在批量往<strong>Redis</strong>存数据的时候，把每个Key的失效时间都加个随机值就好了，这样可以保证数据不会在同一时间大面积失效。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setRedis（Key，value，time + Math.random() * 10000）；</span><br></pre></td></tr></table></figure>

<p>如果<strong>Redis</strong>是集群部署，将热点数据均匀分布在不同的<strong>Redis</strong>库中也能避免全部失效的问题，不过本渣我在生产环境中操作集群的时候，单个服务都是对应的单个<strong>Redis</strong>分片，是为了方便数据的管理，但是也同样有了可能会失效这样的弊端，失效时间随机是个好策略。</p>
<p>或者设置热点数据永远不过期，有更新操作就更新缓存就好了（比如运维更新了首页商品，那你刷下缓存就完事了，不要设置过期时间），电商首页的数据也可以用这个操作，保险。</p>
<h3 id="Redis缓存击穿和穿透"><a href="#Redis缓存击穿和穿透" class="headerlink" title="Redis缓存击穿和穿透"></a>Redis缓存击穿和穿透</h3><p><strong>缓存穿透</strong>是指缓存和数据库中都没有的数据，而用户不断发起请求，我们数据库的 id 都是1开始自增上去的，如发起为id值为 -1 的数据或 id 为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大，严重会击垮数据库。</p>
<p><strong>缓存击穿</strong>嘛，这个跟<strong>缓存雪崩</strong>有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿不同的是<strong>缓存击穿</strong>是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。</p>
<p>解决方案：</p>
<p>在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id &lt;=0的直接拦截等。</p>
<p>从缓存取不到的数据，在数据库中也没有取到，这时也可以将对应Key的Value对写为null、位置错误、稍后重试这样的值</p>
<p>这样可以防止攻击用户反复用同一个id暴力攻击，但是我们要知道正常用户是不会在单秒内发起这么多次请求的，那网关层<strong>Nginx</strong>本渣我也记得有配置项，可以让运维大大对单个IP每秒访问次数超出阈值的IP都拉黑。</p>
<p><strong>Redis</strong>还有一个高级用法<strong>布隆过滤器（Bloom Filter）</strong>这个也能很好的防止缓存穿透的发生，他的原理也很简单就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。</p>
<p><strong>缓存击穿</strong>的话，设置热点数据永远不过期。或者加上互斥锁就能搞定了</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/nanchenkunkun.github.io/images/1.jpg">
      <meta itemprop="name" content="zkk">
      <meta itemprop="description" content="只有变光,才能变强">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kkの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/" class="post-title-link" itemprop="url">Redis集群之布隆过滤器</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-09-08 11:28:53 / 修改时间：11:33:14" itemprop="dateCreated datePublished" datetime="2020-09-08T11:28:53+08:00">2020-09-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">中间件</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/" itemprop="url" rel="index"><span itemprop="name">redis</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h1><p><strong>1、数据结构</strong></p>
<p>布隆过滤器是一个BIT数组，本质上是一个数据，所以可以根据下标快速找数据</p>
<p><img src="img%5C1.png"></p>
<h2 id="2、哈希映射"><a href="#2、哈希映射" class="headerlink" title="2、哈希映射"></a>2、哈希映射</h2><p>1、布隆需要记录见过的数据，这里的记录需要通过hash函数对数据进行hash操作，得到数组下标并存储在BIT 数组里记为1。这样的记录一个数据只占用1BIT空间</p>
<p>2、判断是否存在时：给布隆过滤器一个数据，进行hash得到下标，从BIT数组里取数据如果是1 则说明数据存在，如果是0 说明不存在</p>
<h2 id="3、精确度"><a href="#3、精确度" class="headerlink" title="3、精确度"></a>3、精确度</h2><p>hash算法存在碰撞的可能，所以不同的数据可能hash为一个下标数据，故为了提高精确度就需要 使用多个hash 算法标记一个数据，和增大BIT数组的大小</p>
<p>也是因为如此，布隆过滤器判断为【数据存在】 可能数据并不存在，但是如果判断为【数据不存在】那么数据就一定是不存在的。</p>
<h2 id="4、详细介绍"><a href="#4、详细介绍" class="headerlink" title="4、详细介绍"></a>4、详细介绍</h2><p><strong>1.什么是布隆过滤器</strong></p>
<p>​        本质上布隆过滤器是一种数据结构，比较巧妙的<code>概率型数据结构</code>，特点是<code>高效地插入和查询</code>。根据查询结果可以用来告诉你 <code>某样东西一定不存在或者可能存在</code> 这句话是该算法的核心。</p>
<p>相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的，同时布隆过滤器还有一个缺陷就是</p>
<p><code>数据只能插入不能删除</code>。</p>
<h4 id="2、数据如何存入布隆过滤器"><a href="#2、数据如何存入布隆过滤器" class="headerlink" title="2、数据如何存入布隆过滤器"></a>2、数据如何存入布隆过滤器</h4><p>布隆过滤器是<code>由一个很长的bit数组和一系列哈希函数组成的</code>。</p>
<p><strong>数组的每个元素都只占1bit空间，并且每个元素只能为0或1。</strong></p>
<p>布隆过滤器还拥有k个哈希函数，当一个元素加入布隆过滤器时，会使用k个哈希函数对其进行k次计算,得到k个哈希值，并且根据得到的哈希值，在维数组中把对应下标的值置位1。</p>
<p><strong>判断某个数是否在布隆过滤器中，就对该元素进行k次哈希计算，得到的值在位数组中判断每个元素是否都为1，如果每个元素都为1，就说明这个值在布隆过滤器中。</strong></p>
<h4 id="3、布隆过滤器为什么会有误判"><a href="#3、布隆过滤器为什么会有误判" class="headerlink" title="3、布隆过滤器为什么会有误判"></a>3、布隆过滤器为什么会有误判</h4><p>当插入的元素越来越多时，当一个不在布隆过滤器中的元素，经过同样规则的哈希计算之后，得到的值在位数组中查询，有可能这些位置因为其他的元素先被置1了。（hash冲突）</p>
<p>所以布隆过滤器存在误判的情况，但是<strong>如果布隆过滤器判断某个元素不在布隆过滤器中，那么这个值就一定不在</strong>。</p>
<h4 id="4、使用场景"><a href="#4、使用场景" class="headerlink" title="4、使用场景"></a>4、使用场景</h4><ul>
<li><strong>网页爬虫对URL的去重</strong>，避免爬去相同的URL地址。</li>
<li><strong>垃圾邮件过滤</strong>，从数十亿个垃圾邮件列表中判断某邮箱是否是杀垃圾邮箱。</li>
<li><strong>解决数据库缓存击穿</strong>，黑客攻击服务器时，会构建大量不存在于缓存中的key向服务器发起请求，在数据量足够大的时候，频繁的数据库查询会导致挂机。</li>
<li><strong>秒杀系统</strong>，查看用户是否重复购买。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/%E5%93%A8%E5%85%B5%E3%80%81%E6%8C%81%E4%B9%85%E5%8C%96%E3%80%81%E4%B8%BB%E4%BB%8E/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/nanchenkunkun.github.io/images/1.jpg">
      <meta itemprop="name" content="zkk">
      <meta itemprop="description" content="只有变光,才能变强">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kkの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/%E5%93%A8%E5%85%B5%E3%80%81%E6%8C%81%E4%B9%85%E5%8C%96%E3%80%81%E4%B8%BB%E4%BB%8E/" class="post-title-link" itemprop="url">reids哨兵，持久化，主从</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-09-08 11:28:53" itemprop="dateCreated datePublished" datetime="2020-09-08T11:28:53+08:00">2020-09-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-09-17 09:21:30" itemprop="dateModified" datetime="2020-09-17T09:21:30+08:00">2020-09-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">中间件</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/" itemprop="url" rel="index"><span itemprop="name">redis</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Redis为什么快"><a href="#Redis为什么快" class="headerlink" title="Redis为什么快"></a>Redis为什么快</h3><p><strong>Redis</strong>采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到100000+的<strong>QPS（每秒内查询次数）</strong>。</p>
<ul>
<li>完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。它的，数据存在内存中，类似于<strong>HashMap</strong>，<strong>HashMap</strong>的优势就是查找和操作的时间复杂度都是O(1)；</li>
<li>数据结构简单，对数据操作也简单，<strong>Redis</strong>中的数据结构是专门进行设计的；</li>
<li>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 <strong>CPU</strong>，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；</li>
<li>使用多路I/O复用模型，非阻塞IO；</li>
<li>使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，<strong>Redis</strong>直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；</li>
</ul>
<h3 id="Redis的持久化"><a href="#Redis的持久化" class="headerlink" title="Redis的持久化"></a>Redis的持久化</h3><p>持久化的话是<strong>Redis</strong>高可用中比较重要的一个环节，因为<strong>Redis</strong>数据在内存的特性，持久化必须得有。</p>
<ul>
<li>RDB：<strong>RDB</strong> 持久化机制，是对 <strong>Redis</strong> 中的数据执行<strong>周期性</strong>的持久化。</li>
<li>AOF：<strong>AOF</strong> 机制对每条写入命令作为日志，以 <strong>append-only</strong> 的模式写入一个日志文件中，因为这个模式是只追加的方式，所以没有任何磁盘寻址的开销，所以很快，有点像Mysql中的<strong>binlog</strong>。</li>
</ul>
<p>两种方式都可以把<strong>Redis</strong>内存中的数据持久化到磁盘上，然后再将这些数据备份到别的地方去，<strong>RDB</strong>更适合做<strong>冷备</strong>，<strong>AOF</strong>更适合做<strong>热备</strong>，比如我杭州的某电商公司有这两个数据，我备份一份到我杭州的节点，再备份一个到上海的，就算发生无法避免的自然灾害，也不会两个地方都一起挂吧，这<strong>灾备</strong>也就是<strong>异地容灾</strong>，地球毁灭他没办法。</p>
<p><strong>tip：两种机制全部开启的时候，Redis在重启的时候会默认使用AOF去重新构建数据，因为AOF的数据是比RDB更完整的。</strong></p>
<p>两种持久化方式的优缺点：</p>
<p><strong>RDB</strong></p>
<h4 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h4><p>他会生成多个数据文件，每个数据文件分别都代表了某一时刻<strong>Redis</strong>里面的数据，这种方式，有没有觉得很适合做<strong>冷备</strong>，完整的数据运维设置定时任务，定时同步到远端的服务器，比如阿里的云服务，这样一旦线上挂了，你想恢复多少分钟之前的数据，就去远端拷贝一份之前的数据就好了。</p>
<p><strong>RDB</strong>对<strong>Redis</strong>的性能影响非常小，是因为在同步数据的时候他只是<strong>fork</strong>了一个子进程去做持久化的，而且他在数据恢复的时候速度比<strong>AOF</strong>来的快。</p>
<h4 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h4><p><strong>RDB</strong>都是快照文件，都是默认五分钟甚至更久的时间才会生成一次，这意味着你这次同步到下次同步这中间五分钟的数据都很可能全部丢失掉。<strong>AOF</strong>则最多丢一秒的数据，<strong>数据完整性</strong>上高下立判。</p>
<p>还有就是<strong>RDB</strong>在生成数据快照的时候，如果文件很大，客户端可能会暂停几毫秒甚至几秒，你公司在做秒杀的时候他刚好在这个时候<strong>fork</strong>了一个子进程去生成一个大快照，哦豁，出大问题。</p>
<p><strong>AOF</strong></p>
<h4 id="优点：-1"><a href="#优点：-1" class="headerlink" title="优点："></a>优点：</h4><p>上面提到了，<strong>RDB</strong>五分钟一次生成快照，但是<strong>AOF</strong>是一秒一次去通过一个后台的线程<code>fsync</code>操作，那最多丢这一秒的数据。</p>
<p><strong>AOF</strong>在对日志文件进行操作的时候是以<code>append-only</code>的方式去写的，他只是追加的方式写数据，自然就少了很多磁盘寻址的开销了，写入性能惊人，文件也不容易破损。</p>
<p><strong>AOF</strong>的日志是通过一个叫<strong>非常可读</strong>的方式记录的，这样的特性就适合做<strong>灾难性数据误删除</strong>的紧急恢复了，比如公司的实习生通过<strong>flushall</strong>清空了所有的数据，只要这个时候后台重写还没发生，你马上拷贝一份<strong>AOF</strong>日志文件，把最后一条<strong>flushall</strong>命令删了就完事了。</p>
<h4 id="缺点：-1"><a href="#缺点：-1" class="headerlink" title="缺点："></a>缺点：</h4><p>一样的数据，<strong>AOF</strong>文件比<strong>RDB</strong>还要大。</p>
<p><strong>AOF</strong>开启后，<strong>Redis</strong>支持写的<strong>QPS</strong>会比<strong>RDB</strong>支持写的要低，他不是每秒都要去异步刷新一次日志嘛<strong>fsync</strong>，当然即使这样性能还是很高，我记得<strong>ElasticSearch</strong>也是这样的，异步刷新缓存区的数据去持久化。</p>
<p>单独用<strong>RDB</strong>会丢失很多数据，单独用<strong>AOF</strong>，数据恢复没<strong>RDB</strong>来的快，真出什么事情第一时间用<strong>RDB</strong>恢复，然后<strong>AOF</strong>做数据补全。</p>
<p><strong>哨兵模式：</strong></p>
<p>哨兵必须用三个实例去保证自己的健壮性的，哨兵+主从并<strong>不能保证数据不丢失</strong>，但是可以保证集群的<strong>高可用</strong>。</p>
<p>为啥必须要三个实例呢？我们先看看两个哨兵会咋样。</p>
<p>master宕机了 s1和s2两个哨兵只要有一个认为你宕机了就切换了，并且会选举出一个哨兵去执行故障，但是这个时候也需要大多数哨兵都是运行的。</p>
<p>那这样有啥问题呢？M1宕机了，S1没挂那其实是OK的，但是整个机器都挂了呢？哨兵就只剩下S2个裸了，没有哨兵去允许故障转移了，虽然另外一个机器上还有R1，但是故障转移就是不执行。</p>
<p>经典的哨兵集群是这样的：</p>
<p>M1所在的机器挂了，哨兵还有两个，两个人一看他不是挂了嘛，那我们就选举一个出来执行故障转移不就好了。</p>
<p>哨兵组件的主要功能：</p>
<ul>
<li>集群监控：负责监控 Redis master 和 slave 进程是否正常工作。</li>
<li>消息通知：如果某个 <strong>Redis</strong> 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。</li>
<li>故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。</li>
<li>配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。</li>
</ul>
<h3 id="主从之间的数据同步"><a href="#主从之间的数据同步" class="headerlink" title="主从之间的数据同步"></a>主从之间的数据同步</h3><p>前面提到了单机<strong>QPS</strong>是有上限的，而且<strong>Redis</strong>的特性就是必须支撑读高并发的，那你一台机器又读又写，一般是顶不住的，但是你让这个master机器去写，数据同步给别的slave机器，他们都拿去读，分发掉大量的请求那是不是好很多，而且扩容的时候还可以轻松实现水平扩容。</p>
<p>你启动一台slave 的时候，他会发送一个<strong>psync</strong>命令给master ，如果是这个slave第一次连接到master，他会触发一个全量复制。master就会启动一个线程，生成<strong>RDB</strong>快照，还会把新的写请求都缓存在内存中，<strong>RDB</strong>文件生成后，master会将这个<strong>RDB</strong>发送给slave的，slave拿到之后做的第一件事情就是写进本地的磁盘，然后加载进内存，然后master会把内存里面缓存的那些新命名都发给slave。</p>
<h3 id="内存淘汰机制"><a href="#内存淘汰机制" class="headerlink" title="内存淘汰机制"></a>内存淘汰机制</h3><p>redis的过期策略： 定期删除 +　惰性删除</p>
<p><strong>定期删除</strong>：默认100ms就随机抽一些设置了过期时间的key，去检查是否过期，过期了就删了</p>
<p><strong>惰性删除</strong>：等用户主动查询后，确认过期了就删除。</p>
<p>存在定期没删除，也没查询：</p>
<p><strong>内存淘汰机制</strong>！</p>
<p>官网上给到的内存淘汰机制是以下几个：</p>
<ul>
<li><p><strong>noeviction</strong>:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）</p>
</li>
<li><p><strong>allkeys-lru</strong>: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。</p>
</li>
<li><p><strong>volatile-lru</strong>: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。</p>
</li>
<li><p><strong>allkeys-random</strong>: 回收随机的键使得新添加的数据有空间存放。</p>
</li>
<li><p><strong>volatile-random</strong>: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。</p>
</li>
<li><p><strong>volatile-ttl</strong>: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。</p>
<p>如果没有键满足回收的前提条件的话，策略<strong>volatile-lru</strong>, <strong>volatile-random</strong>以及<strong>volatile-ttl</strong>就和noeviction 差不多了。</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E3%80%81%E5%B9%B6%E5%8F%91%E7%AB%9E%E4%BA%89%E3%80%81%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/nanchenkunkun.github.io/images/1.jpg">
      <meta itemprop="name" content="zkk">
      <meta itemprop="description" content="只有变光,才能变强">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kkの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E3%80%81%E5%B9%B6%E5%8F%91%E7%AB%9E%E4%BA%89%E3%80%81%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7/" class="post-title-link" itemprop="url">Redis分布式锁、并发、双写一致性</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-09-08 11:28:53 / 修改时间：11:35:15" itemprop="dateCreated datePublished" datetime="2020-09-08T11:28:53+08:00">2020-09-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">中间件</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/" itemprop="url" rel="index"><span itemprop="name">redis</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="redis几种数据类型使用场景"><a href="#redis几种数据类型使用场景" class="headerlink" title="redis几种数据类型使用场景"></a>redis几种数据类型使用场景</h3><p><strong>String：</strong></p>
<p>这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。</p>
<p>但是真实的开发环境中，很多人可能会把很多比较复杂的结构也统一转成<strong>String</strong>去存储使用，比如有的仔他就喜欢把对象或者<strong>List</strong>转换为<strong>JSONString</strong>进行存储，拿出来再反序列话啥的。</p>
<p><strong>String</strong>的实际应用场景比较广泛的有：</p>
<ul>
<li><strong>缓存功能：String</strong>字符串是最常用的数据类型，不仅仅是<strong>Redis</strong>，各个语言都是最基本类型，因此，利用<strong>Redis</strong>作为缓存，配合其它数据库作为存储层，利用<strong>Redis</strong>支持高并发的特点，可以大大加快系统的读写速度、以及降低后端数据库的压力。</li>
<li><strong>计数器：</strong>许多系统都会使用<strong>Redis</strong>作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。</li>
<li><strong>共享用户Session：</strong>用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存<strong>Cookie</strong>，但是可以利用<strong>Redis</strong>将用户的<strong>Session</strong>集中管理，在这种模式只需要保证<strong>Redis</strong>的高可用，每次用户<strong>Session</strong>的更新和获取都可以快速完成。大大提高效率。</li>
</ul>
<p><strong>Hash：</strong></p>
<p>这个是类似 <strong>Map</strong> 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是<strong>这个对象没嵌套其他的对象</strong>）给缓存在 <strong>Redis</strong> 里，然后每次读写缓存的时候，可以就操作 <strong>Hash</strong> 里的<strong>某个字段</strong>。</p>
<p>但是这个的场景其实还是多少单一了一些，因为现在很多对象都是比较复杂的，比如你的商品对象可能里面就包含了很多属性，其中也有对象。我自己使用的场景用得不是那么多。</p>
<p><strong>List：</strong></p>
<p><strong>List</strong> 是有序列表，这个还是可以玩儿出很多花样的。</p>
<p>比如可以通过 <strong>List</strong> 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。</p>
<p>比如可以通过 <strong>lrange</strong> 命令，读取某个闭区间内的元素，可以基于 <strong>List</strong> 实现分页查询，这个是很棒的一个功能，基于 <strong>Redis</strong> 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。</p>
<p>比如可以搞个简单的消息队列，从 <strong>List</strong> 头怼进去，从 <strong>List</strong> 屁股那里弄出来。</p>
<p><strong>List</strong>本身就是我们在开发过程中比较常用的数据结构了，热点数据更不用说了。</p>
<ul>
<li><p><strong>消息队列：Redis</strong>的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过<strong>Lpush</strong>命令从左边插入数据，多个数据消费者，可以使用<strong>BRpop</strong>命令阻塞的“抢”列表尾部的数据。</p>
</li>
<li><p>文章列表或者数据分页展示的应用。</p>
<p>比如，我们常用的博客网站的文章列表，当用户量越来越多时，而且每一个用户都有自己的文章列表，而且当文章多时，都需要分页展示，这时可以考虑使用<strong>Redis</strong>的列表，列表不但有序同时还支持按照范围内获取元素，可以完美解决分页查询功能。大大提高查询效率。</p>
</li>
</ul>
<p><strong>Set：</strong></p>
<p><strong>Set</strong> 是无序集合，会自动去重的那种。</p>
<p>直接基于 <strong>Set</strong> 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 <strong>JVM</strong> 内存里的 <strong>HashSet</strong> 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于<strong>Redis</strong>进行全局的 <strong>Set</strong> 去重。</p>
<p>可以基于 <strong>Set</strong> 玩儿交集、并集、差集的操作，比如交集吧，我们可以把两个人的好友列表整一个交集，看看俩人的共同好友是谁？对吧。</p>
<p>反正这些场景比较多，因为对比很快，操作也简单，两个查询一个<strong>Set</strong>搞定。</p>
<p><strong>Sorted Set：</strong></p>
<p><strong>Sorted set</strong> 是排序的 <strong>Set</strong>，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。</p>
<p>有序集合的使用场景与集合类似，但是set集合不是自动有序的，而<strong>Sorted set</strong>可以利用分数进行成员间的排序，而且是插入时就排序好。所以当你需要一个有序且不重复的集合列表时，就可以选择<strong>Sorted set</strong>数据结构作为选择方案。</p>
<ul>
<li><p>排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。</p>
</li>
<li><p>用<strong>Sorted Sets</strong>来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。</p>
<p>微博热搜榜，就是有个后面的热度值，前面就是名称</p>
</li>
</ul>
<h3 id="并发给redis带来的问题"><a href="#并发给redis带来的问题" class="headerlink" title="并发给redis带来的问题"></a>并发给redis带来的问题</h3><p>系统A、B、C三个系统，分别去操作<strong>Redis</strong>的同一个Key，本来顺序是1，2，3是正常的，但是因为系统A网络突然抖动了一下，B，C在他前面操作了<strong>Redis</strong>，这样数据不就错了么。</p>
<p>就好比下单，支付，退款三个顺序你变了，你先退款，再下单，再支付，那流程就会失败，那数据不就乱了？你订单还没生成你却支付，退款了？明显走不通了，这在线上是很恐怖的事情。</p>
<p><strong>解决方案</strong></p>
<p>某个时刻，多个系统实例都去更新某个 key。可以基于 <strong>Zookeeper</strong> 实现分布式锁。每个系统通过 <strong>Zookeeper</strong> 获取分布式锁，确保同一时间，只能有一个系统实例在操作某个 Key，别人都不允许读和写。</p>
<p>你要写入缓存的数据，都是从 <strong>MySQL</strong> 里查出来的，都得写入 <strong>MySQL</strong> 中，写入<strong>MySQL</strong> 中的时候必须保存一个时间戳，从 <strong>MySQL</strong> 查出来的时候，时间戳也查出来。</p>
<p>每次要<strong>写之前，先判断</strong>一下当前这个 Value 的时间戳是否比缓存里的 Value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。</p>
<h3 id="redis和数据库数据一致性的问题"><a href="#redis和数据库数据一致性的问题" class="headerlink" title="redis和数据库数据一致性的问题"></a>redis和数据库数据一致性的问题</h3><p>一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统<strong>不是严格要求</strong> “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：<strong>读请求和写请求串行化</strong>，串到一个<strong>内存队列</strong>里去。</p>
<p>串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。</p>
<p>把一些列的操作都放到队列里面，顺序肯定不会乱，但是并发高了，这队列很容易阻塞，反而会成为整个系统的弱点。</p>
<p>最经典的缓存+数据库读写的模式，就是 <strong>Cache Aside Pattern</strong></p>
<ul>
<li>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。</li>
<li>更新的时候，<strong>先更新数据库，然后再删除缓存</strong>。</li>
</ul>
<h3 id="为什么是删除缓存，而不是更新缓存"><a href="#为什么是删除缓存，而不是更新缓存" class="headerlink" title="为什么是删除缓存，而不是更新缓存"></a>为什么是删除缓存，而不是更新缓存</h3><p>原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。</p>
<p>比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。</p>
<p>另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于<strong>比较复杂的缓存数据计算的场景</strong>，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，<strong>这个缓存到底会不会被频繁访问到？</strong></p>
<p>举个栗子：一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20 次、100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有<strong>大量的冷数据</strong>。</p>
<p>实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。<strong>用到缓存才去算缓存。</strong></p>
<p>其实删除缓存，而不是更新缓存，就是一个 Lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。</p>
<p>像 <strong>Mybatis</strong>，<strong>Hibernate</strong>，都有懒加载思想。查询一个部门，部门带了一个员工的<strong>List</strong>，没有必要说每次查询部门，都里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。</p>
<h3 id="Redis-和-Memcached-有啥区别。"><a href="#Redis-和-Memcached-有啥区别。" class="headerlink" title="Redis 和 Memcached 有啥区别。"></a>Redis 和 Memcached 有啥区别。</h3><p><strong>Redis</strong> 支持复杂的数据结构：</p>
<p><strong>Redis</strong> 相比 <strong>Memcached</strong> 来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， <strong>Redis</strong> 会是不错的选择。</p>
<p><strong>Redis</strong> 原生支持集群模式：</p>
<p>在 redis3.x 版本中，便能支持 <strong>Cluster</strong> 模式，而 <strong>Memcached</strong> 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。</p>
<p>性能对比：</p>
<p>由于 <strong>Redis</strong> 只使用单核，而 <strong>Memcached</strong> 可以使用多核，所以平均每一个核上 <strong>Redis</strong>在存储小数据时比 <strong>Memcached</strong> 性能更高。而在 100k 以上的数据中，<strong>Memcached</strong> 性能要高于 <strong>Redis</strong>，虽然 <strong>Redis</strong> 最近也在存储大数据的性能上进行优化，但是比起<strong>Remcached</strong>，还是稍有逊色。</p>
<h3 id="Redis-的线程模型"><a href="#Redis-的线程模型" class="headerlink" title="Redis 的线程模型"></a>Redis 的线程模型</h3><p><strong>Redis</strong> 内部使用文件事件处理器 <code>file event handler</code>，这个文件事件处理器是单线程的，所以 <strong>Redis</strong> 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个<strong>Socket</strong>，根据 <strong>Socket</strong> 上的事件来选择对应的事件处理器进行处理。</p>
<p>文件事件处理器的结构包含 4 个部分：</p>
<ul>
<li>多个 <strong>Socket</strong></li>
<li>IO 多路复用程序</li>
<li>文件事件分派器</li>
<li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</li>
</ul>
<p>多个 <strong>Socket</strong> 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 <strong>Socket</strong>，会将 <strong>Socket</strong> 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/Redis%E9%9B%86%E7%BE%A4%E4%B9%8B%E4%B8%BB%E4%BB%8E/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/nanchenkunkun.github.io/images/1.jpg">
      <meta itemprop="name" content="zkk">
      <meta itemprop="description" content="只有变光,才能变强">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kkの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/Redis%E9%9B%86%E7%BE%A4%E4%B9%8B%E4%B8%BB%E4%BB%8E/" class="post-title-link" itemprop="url">Redis集群之主从</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-09-08 11:28:53 / 修改时间：11:33:02" itemprop="dateCreated datePublished" datetime="2020-09-08T11:28:53+08:00">2020-09-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">中间件</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/" itemprop="url" rel="index"><span itemprop="name">redis</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="主从概念"><a href="#主从概念" class="headerlink" title="主从概念"></a>主从概念</h3><ul>
<li>一个master可以拥有多个slave，一个slave又可以拥有多个slave，如此下去，形成了强大的多级服务器集群架构</li>
<li>master用来写数据，slave用来读数据，经统计：网站的读写比率是10:1</li>
<li>通过主从配置可以实现读写分离</li>
<li>master和slave都是一个redis实例(redis服务)</li>
</ul>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">master节点                  192.168.30.128</span><br><span class="line"></span><br><span class="line">slave节点                   192.168.30.129</span><br><span class="line"></span><br><span class="line">slave节点                   192.168.30.130</span><br></pre></td></tr></table></figure>

<p>修改配置</p>
<p>192.168.30.128</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">bind 192.168.30.128               #监听ip，多个ip用空格分隔</span><br><span class="line">daemonize yes               #允许后台启动</span><br><span class="line">logfile &quot;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis.log&quot;                #日志路径</span><br><span class="line">dir &#x2F;data&#x2F;redis                 #数据库备份文件存放目录</span><br><span class="line">masterauth 123456               #slave连接master密码，master可省略</span><br><span class="line">requirepass 123456              #设置master连接密码，slave可省略</span><br><span class="line"></span><br><span class="line">appendonly yes                  #在&#x2F;data&#x2F;redis&#x2F;目录生成appendonly.aof文件，将每一次写操作请求都追加到appendonly.aof 文件中</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>192.168.30.129</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bind 192.168.30.129</span><br><span class="line">daemonize yes</span><br><span class="line">logfile &quot;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis.log&quot;</span><br><span class="line">dir &#x2F;data&#x2F;redis</span><br><span class="line">replicaof 192.168.30.128 6379</span><br><span class="line">masterauth 123456</span><br><span class="line">requirepass 123456</span><br><span class="line">appendonly yes</span><br></pre></td></tr></table></figure>

<p>192.168.30.130</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bind 192.168.30.130</span><br><span class="line">daemonize yes</span><br><span class="line">logfile &quot;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis.log&quot;</span><br><span class="line">dir &#x2F;data&#x2F;redis</span><br><span class="line">replicaof 192.168.30.128 6379</span><br><span class="line">masterauth 123456</span><br><span class="line">requirepass 123456</span><br><span class="line">appendonly yes</span><br></pre></td></tr></table></figure>

<p>在master节点写入的数据，很快就同步到slave节点上，而且在slave节点上无法写入数据。</p>
<h3 id="Redis主从复制原理总结"><a href="#Redis主从复制原理总结" class="headerlink" title="Redis主从复制原理总结"></a>Redis主从复制原理总结</h3><p>和Mysql主从复制的原因一样，Redis虽然读取写入的速度都特别快，但是也会产生读压力特别大的情况。为了分担读压力，Redis支持主从复制，Redis的主从结构可以采用一主多从或者级联结构，Redis主从复制可以根据是否是全量分为全量同步和增量同步。</p>
<h4 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h4><p>Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： </p>
<ul>
<li><p>从服务器连接主服务器，发送SYNC命令； </p>
</li>
<li><p>主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； </p>
</li>
<li><p>主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； </p>
</li>
<li><p>从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； </p>
</li>
<li><p>主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； </p>
</li>
<li><p>从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；</p>
</li>
</ul>
<p><strong>增量同步</strong><br>Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。<br>增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。</p>
<p><strong>Redis主从同步策略</strong><br>主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。</p>
<p><strong>注意点</strong><br>如果多个Slave断线了，需要重启的时候，因为只要Slave启动，就会发送sync请求和主机全量同步，当多个同时出现的时候，可能会导致Master IO剧增宕机。</p>
<p>Redis主从复制的配置十分简单，它可以使从服务器是主服务器的完全拷贝。需要清楚Redis主从复制的几点重要内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1）Redis使用异步复制。但从Redis 2.8开始，从服务器会周期性的应答从复制流中处理的数据量。</span><br><span class="line">2）一个主服务器可以有多个从服务器。</span><br><span class="line">3）从服务器也可以接受其他从服务器的连接。除了多个从服务器连接到一个主服务器之外，多个从服务器也可以连接到一个从服务器上，形成一个图状结构。</span><br><span class="line">4）Redis主从复制不阻塞主服务器端。也就是说当若干个从服务器在进行初始同步时，主服务器仍然可以处理请求。</span><br><span class="line">5）主从复制也不阻塞从服务器端。当从服务器进行初始同步时，它使用旧版本的数据来应对查询请求，假设你在redis.conf配置文件是这么配置的。否则的话，你可以配置当复制流关闭时让从服务器给客户端返回一个错误。但是，当初始同步完成后，需要删除旧的数据集和加载新的数据集，在这个短暂的时间内，从服务器会阻塞连接进来的请求。</span><br><span class="line">6）主从复制可以用来增强扩展性，使用多个从服务器来处理只读的请求（比如，繁重的排序操作可以放到从服务器去做），也可以简单的用来做数据冗余。</span><br><span class="line">7）使用主从复制可以为主服务器免除把数据写入磁盘的消耗：在主服务器的redis.conf文件中配置“避免保存”（注释掉所有“保存“命令），然后连接一个配置为“进行保存”的从服务器即可。但是这个配置要确保主服务器不会自动重启（要获得更多信息请阅读下一段）</span><br></pre></td></tr></table></figure>

<h4 id="主从复制的一些特点"><a href="#主从复制的一些特点" class="headerlink" title="主从复制的一些特点"></a>主从复制的一些特点</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1）采用异步复制；</span><br><span class="line">2）一个主redis可以含有多个从redis；</span><br><span class="line">3）每个从redis可以接收来自其他从redis服务器的连接；</span><br><span class="line">4）主从复制对于主redis服务器来说是非阻塞的，这意味着当从服务器在进行主从复制同步过程中，主redis仍然可以处理外界的访问请求；</span><br><span class="line">5）主从复制对于从redis服务器来说也是非阻塞的，这意味着，即使从redis在进行主从复制过程中也可以接受外界的查询请求，只不过这时候从redis返回的是以前老的数据，如果你不想这样，那么在启动redis时，可以在配置文件中进行设置，那么从redis在复制同步过程中来自外界的查询请求都会返回错误给客户端；（虽然说主从复制过程中对于从redis是非阻塞的，但是当从redis从主redis同步过来最新的数据后还需要将新数据加载到内存中，在加载到内存的过程中是阻塞的，在这段时间内的请求将会被阻，但是即使对于大数据集，加载到内存的时间也是比较多的）；</span><br><span class="line">6）主从复制提高了redis服务的扩展性，避免单个redis服务器的读写访问压力过大的问题，同时也可以给为数据备份及冗余提供一种解决方案；</span><br><span class="line">7）为了编码主redis服务器写磁盘压力带来的开销，可以配置让主redis不在将数据持久化到磁盘，而是通过连接让一个配置的从redis服务器及时的将相关数据持久化到磁盘，不过这样会存在一个问题，就是主redis服务器一旦重启，因为主redis服务器数据为空，这时候通过主从同步可能导致从redis服务器上的数据也被清空；</span><br></pre></td></tr></table></figure>

<p><strong>Redis大概主从同步是怎么实现的？</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">全量同步：</span><br><span class="line">master服务器会开启一个后台进程用于将redis中的数据生成一个rdb文件，与此同时，服务器会缓存所有接收到的来自客户端的写命令（包含增、删、改），当后台保存进程</span><br><span class="line">处理完毕后，会将该rdb文件传递给slave服务器，而slave服务器会将rdb文件保存在磁盘并通过读取该文件将数据加载到内存，在此之后master服务器会将在此期间缓存的命令通过redis传输协议发送给slave服务器，然后slave服务器将这些命令依次作用于自己本地的数据集上最终达到数据的一致性。</span><br><span class="line"> </span><br><span class="line">部分同步：</span><br><span class="line">从redis 2.8版本以前，并不支持部分同步，当主从服务器之间的连接断掉之后，master服务器和slave服务器之间都是进行全量数据同步，但是从redis 2.8开始，即使主从连接中途断掉，也不需要进行全量同步，因为从这个版本开始融入了部分同步的概念。部分同步的实现依赖于在master服务器内存中给每个slave服务器维护了一份同步日志和同步标识，每个slave服务器在跟master服务器进行同步时都会携带自己的同步标识和上次同步的最后位置。当主从连接断掉之后，slave服务器隔断时间（默认1s）主动尝试和master服务器进行连接，如果从服务器携带的偏移量标识还在master服务器上的同步备份日志中，那么就从slave发送的偏移量开始继续上次的同步操作，如果slave发送的偏移量已经不再master的同步备份日志中（可能由于主从之间断掉的时间比较长或者在断掉的短暂时间内master服务器接收到大量的写操作），则必须进行一次全量更新。在部分同步过程中，master会将本地记录的同步备份日志中记录的指令依次发送给slave服务器从而达到数据一致。</span><br></pre></td></tr></table></figure>

<h4 id="主从同步中需要注意几个问题"><a href="#主从同步中需要注意几个问题" class="headerlink" title="主从同步中需要注意几个问题"></a><strong>主从同步中需要注意几个问题</strong></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1）在上面的全量同步过程中，master会将数据保存在rdb文件中然后发送给slave服务器，但是如果master上的磁盘空间有限怎么办呢？那么此时全部同步对于master来说将是一份十分有压力的操作了。此时可以通过无盘复制来达到目的，由master直接开启一个socket将rdb文件发送给slave服务器。（无盘复制一般应用在磁盘空间有限但是网络状态良好的情况下）</span><br><span class="line"> </span><br><span class="line">2）主从复制结构，一般slave服务器不能进行写操作，但是这不是死的，之所以这样是为了更容易的保证主和各个从之间数据的一致性，如果slave服务器上数据进行了修改，那么要保证所有主从服务器都能一致，可能在结构上和处理逻辑上更为负责。不过你也可以通过配置文件让从服务器支持写操作。（不过所带来的影响还得自己承担哦。。。）</span><br><span class="line"> </span><br><span class="line">3）主从服务器之间会定期进行通话，但是如果master上设置了密码，那么如果不给slave设置密码就会导致slave不能跟master进行任何操作，所以如果你的master服务器上有密码，那么也给slave相应的设置一下密码吧（通过设置配置文件中的masterauth）;</span><br><span class="line"> </span><br><span class="line">4）关于slave服务器上过期键的处理，由master服务器负责键的过期删除处理，然后将相关删除命令已数据同步的方式同步给slave服务器，slave服务器根据删除命令删除本地的key。</span><br></pre></td></tr></table></figure>



<h4 id="当主服务器不进行持久化时复制的安全性"><a href="#当主服务器不进行持久化时复制的安全性" class="headerlink" title="当主服务器不进行持久化时复制的安全性"></a>当主服务器不进行持久化时复制的安全性</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">在进行主从复制设置时，强烈建议在主服务器上开启持久化，当不能这么做时，比如考虑到延迟的问题，应该将实例配置为避免自动重启。</span><br><span class="line"> </span><br><span class="line">为什么不持久化的主服务器自动重启非常危险呢？</span><br><span class="line">为了更好的理解这个问题，看下面这个失败的例子，其中主服务器和从服务器中数据库都被删除了。</span><br><span class="line"> </span><br><span class="line">设置节点A为主服务器，关闭持久化，节点B和C从节点A复制数据。</span><br><span class="line">这时出现了一个崩溃，但Redis具有自动重启系统，重启了进程，因为关闭了持久化，节点重启后只有一个空的数据集。</span><br><span class="line">节点B和C从节点A进行复制，现在节点A是空的，所以节点B和C上的复制数据也会被删除。</span><br><span class="line">当在高可用系统中使用Redis Sentinel，关闭了主服务器的持久化，并且允许自动重启，这种情况是很危险的。</span><br><span class="line">比如主服务器可能在很短的时间就完成了重启，以至于Sentinel都无法检测到这次失败，那么上面说的这种失败的情况就发生了。</span><br><span class="line"> </span><br><span class="line">如果数据比较重要，并且在使用主从复制时关闭了主服务器持久化功能的场景中，都应该禁止实例自动重启。</span><br></pre></td></tr></table></figure>



<h3 id="Redis主从复制是如何工作的"><a href="#Redis主从复制是如何工作的" class="headerlink" title="Redis主从复制是如何工作的"></a><strong>Redis主从复制是如何工作的</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">如果设置了一个从服务器，在连接时它发送了一个SYNC命令，不管它是第一次连接还是再次连接都没有关系。</span><br><span class="line"> </span><br><span class="line">然后主服务器开始后台存储，并且开始缓存新连接进来的修改数据的命令。当后台存储完成后，主服务器把数据文件发送到从服务器，从服务器将其保存在磁盘上，然后加载到内存中。然后主服务器把刚才缓存的命令发送到从服务器。这是作为命令流来完成的，并且和Redis协议本身格式相同。</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">当主从服务器之间的连接由于某些原因断开时，从服务器可以自动进行重连接。当有多个从服务器同时请求同步时，主服务器只进行一个后台存储。</span><br><span class="line"> </span><br><span class="line">当连接断开又重新连上之后，一般都会进行一个完整的重新同步，但是从Redis2.8开始，只重新同步一部分也可以。</span><br></pre></td></tr></table></figure>



<h3 id="部分重新同步"><a href="#部分重新同步" class="headerlink" title="部分重新同步"></a>部分重新同步</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">从Redis 2.8开始，如果遭遇连接断开，重新连接之后可以从中断处继续进行复制，而不必重新同步。</span><br><span class="line"> </span><br><span class="line">它的工作原理是这样：</span><br><span class="line">主服务器端为复制流维护一个内存缓冲区（in-memory backlog）。主从服务器都维护一个复制偏移量（replication offset）和master run id ，当连接断开时，从服务器会重新连接上主服务器，然后请求继续复制，假如主从服务器的两个master run id相同，并且指定的偏移量在内存缓冲区中还有效，复制就会从上次中断的点开始继续。如果其中一个条件不满足，就会进行完全重新同步（在2.8版本之前就是直接进行完全重新同步）。因为主运行id不保存在磁盘中，如果从服务器重启了的话就只能进行完全同步了。</span><br><span class="line"> </span><br><span class="line">部分重新同步这个新特性内部使用PSYNC命令，旧的实现中使用SYNC命令。Redis2.8版本可以检测出它所连接的服务器是否支持PSYNC命令，不支持的话使用SYNC命令。</span><br></pre></td></tr></table></figure>



<h4 id="无磁盘复制"><a href="#无磁盘复制" class="headerlink" title="无磁盘复制"></a>无磁盘复制</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">通常来讲，一个完全重新同步需要在磁盘上创建一个RDB文件，然后加载这个文件以便为从服务器发送数据。</span><br><span class="line"> </span><br><span class="line">如果使用比较低速的磁盘，这种操作会给主服务器带来较大的压力。Redis从2.8.18版本开始尝试支持无磁盘的复制。</span><br><span class="line">使用这种设置时，子进程直接将RDB通过网络发送给从服务器，不使用磁盘作为中间存储。</span><br></pre></td></tr></table></figure>



<h4 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">主从复制的配置十分简单：把下面这行加入到从服务器的配置文件中即可。</span><br><span class="line">slaveof 192.168.1.1 6379</span><br><span class="line"> </span><br><span class="line">当然你需要把其中的192.168.1.1 6379替换为你自己的主服务器IP（或者主机名hostname）和端口。另外你可以调用SLAVEOF命令，主服务器就会开始与从服务器同步。</span><br><span class="line"> </span><br><span class="line">关于部分重新同步，还有一些针对复制内存缓冲区的优化参数。查看Redis介质中的Redis.conf示例获得更多信息。</span><br><span class="line"> </span><br><span class="line">使用repl-diskless-sync配置参数来启动无磁盘复制。使用repl-diskless-sync-delay 参数来配置传输开始的延迟时间，以便等待</span><br><span class="line">更多的从服务器连接上来。查看Redis介质中的Redis.conf示例获得更多信息。</span><br></pre></td></tr></table></figure>



<h4 id="只读从服务器"><a href="#只读从服务器" class="headerlink" title="只读从服务器"></a>只读从服务器</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">从Redis 2.6开始，从服务器支持只读模式，并且是默认模式。这个行为是由Redis.conf文件中的slave-read-only 参数控制的，可以在运行中通过CONFIG SET来启用或者禁用。</span><br><span class="line"> </span><br><span class="line">只读的从服务器会拒绝所有写命令，所以对从服务器不会有误写操作。但这不表示可以把从服务器实例暴露在危险的网络环境下，因为像DEBUG或者CONFIG这样的管理命令还是可以运行的。不过你可以通过使用rename-command命令来为这些命令改名来增加安全性。</span><br><span class="line"> </span><br><span class="line">你可能想知道为什么只读限制还可以被还原，使得从服务器还可以进行写操作。虽然当主从服务器进行重新同步或者从服务器重启后，这些写操作都会失效，还是有一些使用场景会想从服务器中写入临时数据的，但将来这个特性可能会被去掉。</span><br></pre></td></tr></table></figure>



<h4 id="限制有N个以上从服务器才允许写入"><a href="#限制有N个以上从服务器才允许写入" class="headerlink" title="限制有N个以上从服务器才允许写入"></a>限制有N个以上从服务器才允许写入</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">从Redis 2.8版本开始，可以配置主服务器连接N个以上从服务器才允许对主服务器进行写操作。但是，因为Redis使用的是异步主从复制，</span><br><span class="line">没办法确保从服务器确实收到了要写入的数据，所以还是有一定的数据丢失的可能性。</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">这一特性的工作原理如下：</span><br><span class="line">1）从服务器每秒钟&#96;&#96;ping&#96;&#96;一次主服务器，确认处理的复制流数量。</span><br><span class="line">2）主服务器记住每个从服务器最近一次&#96;&#96;ping&#96;&#96;的时间。</span><br><span class="line">3）用户可以配置最少要有N个服务器有小于M秒的确认延迟。</span><br><span class="line">4）如果有N个以上从服务器，并且确认延迟小于M秒，主服务器接受写操作。</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">还可以把这看做是CAP原则（一致性，可用性，分区容错性）不严格的一致性实现，虽然不能百分百确保一致性，但至少保证了丢失的数据不会超过M秒内的数据量。</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">如果条件不满足，主服务器会拒绝写操作并返回一个错误。</span><br><span class="line">1）min-slaves-to-write（最小从服务器数）</span><br><span class="line">2）min-slaves-max-lag（从服务器最大确认延迟）</span><br></pre></td></tr></table></figure>



<p>**通过redis实现服务器崩溃等数据恢复  **</p>
<p>由于redis存储在内存中且提供一般编程语言常用的数据结构存储类型，所以经常被用于做服务器崩溃宕机的数据恢复处理。服务器可以在某些指定过程中将需要保存的数据以json对象等方式存储到redis中，也就是我们常说的快照，当服务器运行时读取redis来判断是否有待需要恢复数据继续处理的业务。当一次业务处理结束后再删除redis的数据即可。<strong>redis提供两种将内存数据导出到硬盘实现数据备份的方法</strong>：</p>
<p><strong>1）RDB方式(默认)</strong><br>RDB方式的持久化是通过快照（snapshotting）完成的，当符合一定条件时Redis会自动将内存中的所有数据进行快照并存储在硬盘上。进行快照的条件可以由用户在配置文件中自定义，由两个参数构成：时间和改动的键的个数。当在指定的时间内被更改的键的个数大于指定的数值时就会进行快照。RDB是redis默认采用的持久化方式，在配置文件中已经预置了3个条件：<br>save 900 1      #900秒内有至少1个键被更改则进行快照<br>save 300 10     #300秒内有至少10个键被更改则进行快照<br>save 60 10000   #60秒内有至少10000个键被更改则进行快照</p>
<p>可以存在多个条件，条件之间是”或”的关系，只要满足其中一个条件，就会进行快照。 如果想要禁用自动快照，只需要将所有的save参数删除即可。<br>Redis默认会将快照文件存储在当前目录(可CONFIG GET dir来查看)的dump.rdb文件中，可以通过配置dir和dbfilename两个参数分别指定快照文件的存储路径和文件名。</p>
<p>Redis实现快照的过程<br>-  Redis使用fork函数复制一份当前进程（父进程）的副本（子进程）；<br>-  父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件；<br>-  当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此一次快照操作完成。<br>-  在执行fork的时候操作系统（类Unix操作系统）会使用写时复制（copy-on-write）策略，即fork函数发生的一刻父子进程共享同一内存数据，当父进程要更改其中某片数据时（如执行一个写命令 ），操作系统会将该片数据复制一份以保证子进程的数据不受影响，所以新的RDB文件存储的是执行fork一刻的内存数据。</p>
<p>Redis在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说任何时候RDB文件都是完整的。这使得我们可以通过定时备份RDB文件来实 现Redis数据库备份。RDB文件是经过压缩（可以配置rdbcompression参数以禁用压缩节省CPU占用）的二进制格式，所以占用的空间会小于内存中的数据大小，更加利于传输。</p>
<p>除了自动快照，还可以手动发送SAVE或BGSAVE命令让Redis执行快照，两个命令的区别在于，<strong>前者是由主进程进行快照操作，会阻塞住其他请求，后者会通过fork子进程进行快照操作。</strong> Redis启动后会读取RDB快照文件，将数据从硬盘载入到内存。根据数据量大小与结构和服务器性能不同，这个时间也不同。通常将一个记录一千万个字符串类型键、大小为1GB的快照文件载入到内 存中需要花费20～30秒钟。 通过RDB方式实现持久化，一旦Redis异常退出，就会丢失最后一次快照以后更改的所有数据。这就需要开发者根据具体的应用场合，通过组合设置自动快照条件的方式来将可能发生的数据损失控制在能够接受的范围。如果数据很重要以至于无法承受任何损失，则可以考虑使用AOF方式进行持久化。</p>
<p><strong>2）AOF方式</strong><br>默认情况下Redis没有开启AOF(append only file)方式的持久化，可以在redis.conf中通过appendonly参数开启：</p>
<p>appendonly yes<br>在启动时Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，载入的速度相较RDB会慢一些</p>
<p>开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof，可以通过appendfilename参数修改：</p>
<p>appendfilename appendonly.aof<br>配置redis自动重写AOF文件的条件</p>
<p>auto-aof-rewrite-percentage 100  # 当目前的AOF文件大小超过上一次重写时的AOF文件大小的百分之多少时会再次进行重写，如果之前没有重写过，则以启动时的AOF文件大小为依据</p>
<p>auto-aof-rewrite-min-size 64mb   # 允许重写的最小AOF文件大小<br>配置写入AOF文件后，要求系统刷新硬盘缓存的机制</p>
<p># appendfsync always   # 每次执行写入都会执行同步，最安全也最慢<br>appendfsync everysec   # 每秒执行一次同步操作</p>
<p># appendfsync no       # 不主动进行同步操作，而是完全交由操作系统来做（即每30秒一次），最快也最不安全</p>
<p>Redis允许同时开启AOF和RDB，既保证了数据安全又使得进行备份等操作十分容易。此时重新启动Redis后Redis会使用AOF文件来恢复数据，因为AOF方式的持久化可能丢失的数据更少</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/Redis%E9%9B%86%E7%BE%A4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/nanchenkunkun.github.io/images/1.jpg">
      <meta itemprop="name" content="zkk">
      <meta itemprop="description" content="只有变光,才能变强">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kkの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/Redis%E9%9B%86%E7%BE%A4/" class="post-title-link" itemprop="url">Redis集群</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-09-08 11:28:53 / 修改时间：11:32:38" itemprop="dateCreated datePublished" datetime="2020-09-08T11:28:53+08:00">2020-09-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">中间件</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/" itemprop="url" rel="index"><span itemprop="name">redis</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Redis集群"><a href="#Redis集群" class="headerlink" title="Redis集群"></a>Redis集群</h1><p>redis集群有三种集群模式，分别是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">* 主从模式</span><br><span class="line"></span><br><span class="line">* Sentinel模式</span><br><span class="line"></span><br><span class="line">* Cluster模式</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="主从模式"><a href="#主从模式" class="headerlink" title="主从模式"></a>主从模式</h3><h4 id="主从模式介绍"><a href="#主从模式介绍" class="headerlink" title="主从模式介绍"></a>主从模式介绍</h4><p>主从模式是三种模式中最简单的，在主从复制中，数据库分为两类：主数据库(master)和从数据库(slave)。</p>
<p>其中主从复制有如下特点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">* 主数据库可以进行读写操作，当读写操作导致数据变化时会自动将数据同步给从数据库</span><br><span class="line"></span><br><span class="line">* 从数据库一般都是只读的，并且接收主数据库同步过来的数据</span><br><span class="line"></span><br><span class="line">* 一个master可以拥有多个slave，但是一个slave只能对应一个master</span><br><span class="line"></span><br><span class="line">* slave挂了不影响其他slave的读和master的读和写，重新启动后会将数据从master同步过来</span><br><span class="line"></span><br><span class="line">* master挂了以后，不影响slave的读，但redis不再提供写服务，master重启后redis将重新对外提供写服务</span><br><span class="line"></span><br><span class="line">* master挂了以后，不会在slave节点中重新选一个master</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>工作机制：</p>
<p>当slave启动后，主动向master发送SYNC命令。master接收到SYNC命令后在后台保存快照（RDB持久化）和缓存保存快照这段时间的命令，然后将保存的快照文件和缓存的命令发送给slave。slave接收到快照文件和命令后加载快照文件和缓存的执行命令。</p>
<p>复制初始化后，master每次接收到的写命令都会同步发送给slave，保证主从数据一致性。</p>
<p>安全设置：</p>
<p>当master节点设置密码后，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">客户端访问master需要密码</span><br><span class="line"></span><br><span class="line">启动slave需要密码，在配置文件中配置即可</span><br><span class="line"></span><br><span class="line">客户端访问slave不需要密码</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>缺点：</p>
<p>从上面可以看出，master节点在主从模式中唯一，若master挂掉，则redis无法对外提供写服务。</p>
<h4 id="主从模式搭建"><a href="#主从模式搭建" class="headerlink" title="主从模式搭建"></a>主从模式搭建</h4><ul>
<li>环境准备：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">master节点                  192.168.30.128</span><br><span class="line"></span><br><span class="line">slave节点                   192.168.30.129</span><br><span class="line"></span><br><span class="line">slave节点                   192.168.30.130</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li><p>修改配置：</p>
<p>192.168.30.128</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># mkdir -p &#x2F;data&#x2F;redis</span><br><span class="line"></span><br><span class="line"># vim &#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis.conf</span><br><span class="line"></span><br><span class="line">bind 192.168.30.128               #监听ip，多个ip用空格分隔</span><br><span class="line">daemonize yes               #允许后台启动</span><br><span class="line">logfile &quot;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis.log&quot;                #日志路径</span><br><span class="line">dir &#x2F;data&#x2F;redis                 #数据库备份文件存放目录</span><br><span class="line">masterauth 123456               #slave连接master密码，master可省略</span><br><span class="line">requirepass 123456              #设置master连接密码，slave可省略</span><br><span class="line"></span><br><span class="line">appendonly yes                  #在&#x2F;data&#x2F;redis&#x2F;目录生成appendonly.aof文件，将每一次写操作请求都追加到appendonly.aof 文件中</span><br><span class="line"></span><br><span class="line"># echo &#39;vm.overcommit_memory&#x3D;1&#39; &gt;&gt; &#x2F;etc&#x2F;sysctl.conf</span><br><span class="line"></span><br><span class="line"># sysctl -p</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>192.168.30.129</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># mkdir -p &#x2F;data&#x2F;redis</span><br><span class="line"></span><br><span class="line"># vim &#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis.conf</span><br><span class="line"></span><br><span class="line">bind 192.168.30.129</span><br><span class="line">daemonize yes</span><br><span class="line">logfile &quot;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis.log&quot;</span><br><span class="line">dir &#x2F;data&#x2F;redis</span><br><span class="line">replicaof 192.168.30.128 6379</span><br><span class="line">masterauth 123456</span><br><span class="line">requirepass 123456</span><br><span class="line">appendonly yes</span><br><span class="line"></span><br><span class="line"># echo &#39;vm.overcommit_memory&#x3D;1&#39; &gt;&gt; &#x2F;etc&#x2F;sysctl.conf</span><br><span class="line"></span><br><span class="line"># sysctl -p</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>192.168.30.130</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># mkdir -p &#x2F;data&#x2F;redis</span><br><span class="line"></span><br><span class="line"># vim &#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis.conf</span><br><span class="line"></span><br><span class="line">bind 192.168.30.130</span><br><span class="line">daemonize yes</span><br><span class="line">logfile &quot;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis.log&quot;</span><br><span class="line">dir &#x2F;data&#x2F;redis</span><br><span class="line">replicaof 192.168.30.128 6379</span><br><span class="line">masterauth 123456</span><br><span class="line">requirepass 123456</span><br><span class="line">appendonly yes</span><br><span class="line"></span><br><span class="line"># echo &#39;vm.overcommit_memory&#x3D;1&#39; &gt;&gt; &#x2F;etc&#x2F;sysctl.conf</span><br><span class="line"></span><br><span class="line"># sysctl -p</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在master节点写入的数据，很快就同步到slave节点上，而且在slave节点上无法写入数据。</p>
<h3 id="Sentinel模式"><a href="#Sentinel模式" class="headerlink" title="Sentinel模式"></a>Sentinel模式</h3><h4 id="Sentinel模式介绍"><a href="#Sentinel模式介绍" class="headerlink" title="Sentinel模式介绍"></a>Sentinel模式介绍</h4><p>主从模式的弊端就是不具备高可用性，当master挂掉以后，Redis将不能再对外提供写入操作，因此sentinel应运而生。</p>
<p>sentinel中文含义为哨兵，顾名思义，它的作用就是监控redis集群的运行状况，特点如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">* sentinel模式是建立在主从模式的基础上，如果只有一个Redis节点，sentinel就没有任何意义</span><br><span class="line"></span><br><span class="line">* 当master挂了以后，sentinel会在slave中选择一个做为master，并修改它们的配置文件，其他slave的配置文件也会被修改，比如slaveof属性会指向新的master</span><br><span class="line"></span><br><span class="line">* 当master重新启动后，它将不再是master而是做为slave接收新的master的同步数据</span><br><span class="line"></span><br><span class="line">* sentinel因为也是一个进程有挂掉的可能，所以sentinel也会启动多个形成一个sentinel集群</span><br><span class="line"></span><br><span class="line">* 多sentinel配置的时候，sentinel之间也会自动监控</span><br><span class="line"></span><br><span class="line">* 当主从模式配置密码时，sentinel也会同步将配置信息修改到配置文件中，不需要担心</span><br><span class="line"></span><br><span class="line">* 一个sentinel或sentinel集群可以管理多个主从Redis，多个sentinel也可以监控同一个redis</span><br><span class="line"></span><br><span class="line">* sentinel最好不要和Redis部署在同一台机器，不然Redis的服务器挂了以后，sentinel也挂了</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>工作机制：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">* 每个sentinel以每秒钟一次的频率向它所知的master，slave以及其他sentinel实例发送一个 PING 命令 </span><br><span class="line"></span><br><span class="line">* 如果一个实例距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被sentinel标记为主观下线。 </span><br><span class="line"></span><br><span class="line">* 如果一个master被标记为主观下线，则正在监视这个master的所有sentinel要以每秒一次的频率确认master的确进入了主观下线状态</span><br><span class="line"></span><br><span class="line">* 当有足够数量的sentinel（大于等于配置文件指定的值）在指定的时间范围内确认master的确进入了主观下线状态， 则master会被标记为客观下线 </span><br><span class="line"></span><br><span class="line">* 在一般情况下， 每个sentinel会以每 10 秒一次的频率向它已知的所有master，slave发送 INFO 命令 </span><br><span class="line"></span><br><span class="line">* 当master被sentinel标记为客观下线时，sentinel向下线的master的所有slave发送 INFO 命令的频率会从 10 秒一次改为 1 秒一次 </span><br><span class="line"></span><br><span class="line">* 若没有足够数量的sentinel同意master已经下线，master的客观下线状态就会被移除；</span><br><span class="line">  若master重新向sentinel的 PING 命令返回有效回复，master的主观下线状态就会被移除</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>当使用sentinel模式的时候，客户端就不要直接连接Redis，而是连接sentinel的ip和port，由sentinel来提供具体的可提供服务的Redis实现，这样当master节点挂掉以后，sentinel就会感知并将新的master节点提供给使用者。</p>
<h4 id="Sentinel模式搭建"><a href="#Sentinel模式搭建" class="headerlink" title="Sentinel模式搭建"></a>Sentinel模式搭建</h4><ul>
<li>环境准备：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">master节点              192.168.30.128          sentinel端口：26379</span><br><span class="line"></span><br><span class="line">slave节点               192.168.30.129          sentinel端口：26379</span><br><span class="line"></span><br><span class="line">slave节点               192.168.30.130          sentinel端口：26379</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<ul>
<li>修改配置：</li>
</ul>
<p>前面已经下载安装了redis，这里省略，直接修改sentinel配置文件。</p>
<p>192.168.30.128</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># vim &#x2F;usr&#x2F;local&#x2F;redis&#x2F;sentinel.conf</span><br><span class="line"></span><br><span class="line">daemonize yes</span><br><span class="line">logfile &quot;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;sentinel.log&quot;</span><br><span class="line">dir &quot;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;sentinel&quot;                 #sentinel工作目录</span><br><span class="line">sentinel monitor mymaster 192.168.30.128 6379 2                 #判断master失效至少需要2个sentinel同意，建议设置为n&#x2F;2+1，n为sentinel个数</span><br><span class="line">sentinel auth-pass mymaster 123456</span><br><span class="line">sentinel down-after-milliseconds mymaster 30000                 #判断master主观下线时间，默认30s</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这里需要注意，<code>sentinel auth-pass mymaster 123456</code>需要配置在<code>sentinel monitor mymaster 192.168.30.128 6379 2</code>下面，否则启动报错：</p>
<p>Sentinel模式下的几个事件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">·       +reset-master ：主服务器已被重置。</span><br><span class="line"></span><br><span class="line">·       +slave ：一个新的从服务器已经被 Sentinel 识别并关联。</span><br><span class="line"></span><br><span class="line">·       +failover-state-reconf-slaves ：故障转移状态切换到了 reconf-slaves 状态。</span><br><span class="line"></span><br><span class="line">·       +failover-detected ：另一个 Sentinel 开始了一次故障转移操作，或者一个从服务器转换成了主服务器。</span><br><span class="line"></span><br><span class="line">·       +slave-reconf-sent ：领头（leader）的 Sentinel 向实例发送了 [SLAVEOF](&#x2F;commands&#x2F;slaveof.html) 命令，为实例设置新的主服务器。</span><br><span class="line"></span><br><span class="line">·       +slave-reconf-inprog ：实例正在将自己设置为指定主服务器的从服务器，但相应的同步过程仍未完成。</span><br><span class="line"></span><br><span class="line">·       +slave-reconf-done ：从服务器已经成功完成对新主服务器的同步。</span><br><span class="line"></span><br><span class="line">·       -dup-sentinel ：对给定主服务器进行监视的一个或多个 Sentinel 已经因为重复出现而被移除 —— 当 Sentinel 实例重启的时候，就会出现这种情况。</span><br><span class="line"></span><br><span class="line">·       +sentinel ：一个监视给定主服务器的新 Sentinel 已经被识别并添加。</span><br><span class="line"></span><br><span class="line">·       +sdown ：给定的实例现在处于主观下线状态。</span><br><span class="line"></span><br><span class="line">·       -sdown ：给定的实例已经不再处于主观下线状态。</span><br><span class="line"></span><br><span class="line">·       +odown ：给定的实例现在处于客观下线状态。</span><br><span class="line"></span><br><span class="line">·       -odown ：给定的实例已经不再处于客观下线状态。</span><br><span class="line"></span><br><span class="line">·       +new-epoch ：当前的纪元（epoch）已经被更新。</span><br><span class="line"></span><br><span class="line">·       +try-failover ：一个新的故障迁移操作正在执行中，等待被大多数 Sentinel 选中（waiting to be elected by the majority）。</span><br><span class="line"></span><br><span class="line">·       +elected-leader ：赢得指定纪元的选举，可以进行故障迁移操作了。</span><br><span class="line"></span><br><span class="line">·       +failover-state-select-slave ：故障转移操作现在处于 select-slave 状态 —— Sentinel 正在寻找可以升级为主服务器的从服务器。</span><br><span class="line"></span><br><span class="line">·       no-good-slave ：Sentinel 操作未能找到适合进行升级的从服务器。Sentinel 会在一段时间之后再次尝试寻找合适的从服务器来进行升级，又或者直接放弃执行故障转移操作。</span><br><span class="line"></span><br><span class="line">·       selected-slave ：Sentinel 顺利找到适合进行升级的从服务器。</span><br><span class="line"></span><br><span class="line">·       failover-state-send-slaveof-noone ：Sentinel 正在将指定的从服务器升级为主服务器，等待升级功能完成。</span><br><span class="line"></span><br><span class="line">·       failover-end-for-timeout ：故障转移因为超时而中止，不过最终所有从服务器都会开始复制新的主服务器（slaves will eventually be configured to replicate with the new master anyway）。</span><br><span class="line"></span><br><span class="line">·       failover-end ：故障转移操作顺利完成。所有从服务器都开始复制新的主服务器了。</span><br><span class="line"></span><br><span class="line">·       +switch-master ：配置变更，主服务器的 IP 和地址已经改变。 这是绝大多数外部用户都关心的信息。</span><br><span class="line"></span><br><span class="line">·       +tilt ：进入 tilt 模式。</span><br><span class="line"></span><br><span class="line">·       -tilt ：退出 tilt 模式。</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="Cluster模式"><a href="#Cluster模式" class="headerlink" title="Cluster模式"></a>Cluster模式</h3><h4 id="Cluster模式介绍"><a href="#Cluster模式介绍" class="headerlink" title="Cluster模式介绍"></a>Cluster模式介绍</h4><p>sentinel模式基本可以满足一般生产的需求，具备高可用性。但是当数据量过大到一台服务器存放不下的情况时，主从模式或sentinel模式就不能满足需求了，这个时候需要对存储的数据进行分片，将数据存储到多个Redis实例中。cluster模式的出现就是为了解决单机Redis容量有限的问题，将Redis的数据根据一定的规则分配到多台机器。</p>
<p>cluster可以说是sentinel和主从模式的结合体，通过cluster可以实现主从和master重选功能，所以如果配置两个副本三个分片的话，就需要六个Redis实例。因为Redis的数据是根据一定规则分配到cluster的不同机器的，当数据量过大时，可以新增机器进行扩容。</p>
<p>使用集群，只需要将redis配置文件中的<code>cluster-enable</code>配置打开即可。每个集群中至少需要三个主数据库才能正常运行，新增节点非常方便。</p>
<p>cluster集群特点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">* 多个redis节点网络互联，数据共享</span><br><span class="line"></span><br><span class="line">* 所有的节点都是一主一从（也可以是一主多从），其中从不提供服务，仅作为备用</span><br><span class="line"></span><br><span class="line">* 不支持同时处理多个key（如MSET&#x2F;MGET），因为redis需要把key均匀分布在各个节点上，</span><br><span class="line">  并发量很高的情况下同时创建key-value会降低性能并导致不可预测的行为</span><br><span class="line">  </span><br><span class="line">* 支持在线增加、删除节点</span><br><span class="line"></span><br><span class="line">* 客户端可以连接任何一个主节点进行读写</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="Cluster模式搭建"><a href="#Cluster模式搭建" class="headerlink" title="Cluster模式搭建"></a>Cluster模式搭建</h4><ul>
<li><p>环境准备：</p>
</li>
<li><pre><code>三台机器，分别开启两个redis服务（端口）

192.168.30.128              端口：7001,7002

192.168.30.129              端口：7003,7004

192.168.30.130              端口：7005,7006

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  - 修改配置文件：</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">192.168.30.128</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</code></pre>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="vim-usr-local-redis-cluster-redis-7001-conf"><a href="#vim-usr-local-redis-cluster-redis-7001-conf" class="headerlink" title="vim /usr/local/redis/cluster/redis_7001.conf"></a>vim /usr/local/redis/cluster/redis_7001.conf</h1><p>bind 192.168.30.128<br>port 7001<br>daemonize yes<br>pidfile “/var/run/redis_7001.pid”<br>logfile “/usr/local/redis/cluster/redis_7001.log”<br>dir “/data/redis/cluster/redis_7001”<br>#replicaof 192.168.30.129 6379<br>masterauth 123456<br>requirepass 123456<br>appendonly yes<br>cluster-enabled yes<br>cluster-config-file nodes_7001.conf<br>cluster-node-timeout 15000</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="vim-usr-local-redis-cluster-redis-7002-conf"><a href="#vim-usr-local-redis-cluster-redis-7002-conf" class="headerlink" title="vim /usr/local/redis/cluster/redis_7002.conf"></a>vim /usr/local/redis/cluster/redis_7002.conf</h1><p>bind 192.168.30.128<br>port 7002<br>daemonize yes<br>pidfile “/var/run/redis_7002.pid”<br>logfile “/usr/local/redis/cluster/redis_7002.log”<br>dir “/data/redis/cluster/redis_7002”<br>#replicaof 192.168.30.129 6379<br>masterauth “123456”<br>requirepass “123456”<br>appendonly yes<br>cluster-enabled yes<br>cluster-config-file nodes_7002.conf<br>cluster-node-timeout 15000</p>
<pre><code></code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/Redis%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/nanchenkunkun.github.io/images/1.jpg">
      <meta itemprop="name" content="zkk">
      <meta itemprop="description" content="只有变光,才能变强">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kkの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/Redis%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" class="post-title-link" itemprop="url">redis的数据结构</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-09-08 11:28:53 / 修改时间：11:32:26" itemprop="dateCreated datePublished" datetime="2020-09-08T11:28:53+08:00">2020-09-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">中间件</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/" itemprop="url" rel="index"><span itemprop="name">redis</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="redis的数据结构"><a href="#redis的数据结构" class="headerlink" title="redis的数据结构"></a>redis的数据结构</h3><p><strong>String</strong>、<strong>Hash</strong>、<strong>List</strong>、<strong>Set</strong>、<strong>SortedSet</strong>。</p>
<p>但是，如果你是Redis中高级用户，而且你要在这次面试中突出你和其他候选人的不同，还需要加上下面几种数据结构<strong>HyperLogLog、Geo、Pub/Sub</strong>。</p>
<p>如果你还想加分，那你说还玩过<strong>Redis Module</strong>，像<strong>BloomFilter，RedisSearch，Redis-ML，</strong></p>
<h3 id="如果有大量的key需要设置同一时间过期，一般需要注意什么？"><a href="#如果有大量的key需要设置同一时间过期，一般需要注意什么？" class="headerlink" title="如果有大量的key需要设置同一时间过期，一般需要注意什么？"></a>如果有大量的key需要设置同一时间过期，一般需要注意什么？</h3><p>如果大量的key过期时间设置的过于集中，到过期的那个时间点，<strong>Redis</strong>可能会出现短暂的卡顿现象。严重的话会出现缓存雪崩，我们一般需要在时间上加一个随机值，使得过期时间分散一些。</p>
<p><strong>电商首页经常会使用定时任务刷新缓存，可能大量的数据失效时间都十分集中，如果失效时间一样，又刚好在失效的时间点大量用户涌入，就有可能造成缓存雪崩</strong></p>
<h3 id="那你使用过Redis分布式锁么，它是什么回事？"><a href="#那你使用过Redis分布式锁么，它是什么回事？" class="headerlink" title="那你使用过Redis分布式锁么，它是什么回事？"></a>那你使用过Redis分布式锁么，它是什么回事？</h3><p>先拿<strong>setnx</strong>来争抢锁，抢到之后，再用<strong>expire</strong>给锁加一个过期时间防止锁忘记了释放。</p>
<h3 id="如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？"><a href="#如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？" class="headerlink" title="如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？"></a>如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？</h3><p>set指令有非常复杂的参数，这个应该是可以同时把<strong>setnx</strong>和<strong>expire</strong>合成一条指令来用的！</p>
<h3 id="假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？"><a href="#假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？" class="headerlink" title="假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？"></a>假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？</h3><p>使用<strong>keys</strong>指令可以扫出指定模式的key列表。</p>
<h3 id="如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？"><a href="#如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？" class="headerlink" title="如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？"></a>如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？</h3><p>Redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用<strong>scan</strong>指令，<strong>scan</strong>指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。</p>
<p><strong>不过，增量式迭代命令也不是没有缺点的：举个例子， 使用 SMEMBERS 命令可以返回集合键当前包含的所有元素， 但是对于 SCAN 这类增量式迭代命令来说， 因为在对键进行增量式迭代的过程中， 键可能会被修改， 所以增量式迭代命令只能对被返回的元素提供有限的保证 。</strong></p>
<h3 id="使用过Redis做异步队列么，怎么用的？"><a href="#使用过Redis做异步队列么，怎么用的？" class="headerlink" title="使用过Redis做异步队列么，怎么用的？"></a>使用过Redis做异步队列么，怎么用的？</h3><p>一般使用list结构作为队列，<strong>rpush</strong>生产消息，<strong>lpop</strong>消费消息。当lpop没有消息的时候，要适当sleep一会再重试。</p>
<h3 id="Redis如何实现延时队列"><a href="#Redis如何实现延时队列" class="headerlink" title="Redis如何实现延时队列"></a>Redis如何实现延时队列</h3><p>使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用<strong>zrangebyscore</strong>指令获取N秒之前的数据轮询进行处理。</p>
<h3 id="Redis是怎么持久化的？服务主从数据怎么交互的？"><a href="#Redis是怎么持久化的？服务主从数据怎么交互的？" class="headerlink" title="Redis是怎么持久化的？服务主从数据怎么交互的？"></a>Redis是怎么持久化的？服务主从数据怎么交互的？</h3><p>RDB做镜像全量持久化，AOF做增量持久化。因为RDB会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要AOF来配合使用。在redis实例重启时，会使用RDB持久化文件重新构建内存，再使用AOF重放近期的操作指令来实现完整恢复重启之前的状态。</p>
<p><strong>这里很好理解，把RDB理解为一整个表全量的数据，AOF理解为每次操作的日志就好了，服务器重启的时候先把表的数据全部搞进去，但是他可能不完整，你再回放一下日志，数据不就完整了嘛。不过Redis本身的机制是 AOF持久化开启且存在AOF文件时，优先加载AOF文件；AOF关闭或者AOF文件不存在时，加载RDB文件；加载AOF/RDB文件城后，Redis启动成功；AOF/RDB文件存在错误时，Redis启动失败并打印错误信息</strong></p>
<h3 id="RDB的原理是什么"><a href="#RDB的原理是什么" class="headerlink" title="RDB的原理是什么"></a>RDB的原理是什么</h3><p>你给出两个词汇就可以了，fork和cow。fork是指redis通过创建子进程来进行RDB操作，cow指的是<strong>copy on write</strong>，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。</p>
<h3 id="Pipeline有什么好处，为什么要用pipeline？"><a href="#Pipeline有什么好处，为什么要用pipeline？" class="headerlink" title="Pipeline有什么好处，为什么要用pipeline？"></a>Pipeline有什么好处，为什么要用pipeline？</h3><p>可以将多次IO往返的时间缩减为一次，前提是<strong>pipeline</strong>执行的指令之间没有因果相关性。使用<strong>redis-benchmark</strong>进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是<strong>pipeline</strong>批次指令的数目。</p>
<h3 id="Redis的同步机制"><a href="#Redis的同步机制" class="headerlink" title="Redis的同步机制"></a>Redis的同步机制</h3><p>Redis可以使用主从同步，从从同步。第一次同步时，主节点做一次<strong>bgsave</strong>，并同时将后续修改操作记录到内存buffer，待完成后将RDB文件全量同步到复制节点，复制节点接受完成后将RDB镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。后续的增量数据通过AOF日志同步即可，有点类似数据库的binlog。</p>
<h3 id="Redis集群，集群的高可用怎么保证，集群的原理是什么？"><a href="#Redis集群，集群的高可用怎么保证，集群的原理是什么？" class="headerlink" title="Redis集群，集群的高可用怎么保证，集群的原理是什么？"></a>Redis集群，集群的高可用怎么保证，集群的原理是什么？</h3><p><strong>Redis Sentinal</strong> 着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。</p>
<p><strong>Redis Cluster</strong> 着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/Redis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/nanchenkunkun.github.io/images/1.jpg">
      <meta itemprop="name" content="zkk">
      <meta itemprop="description" content="只有变光,才能变强">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kkの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/Redis/" class="post-title-link" itemprop="url">Redis</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-09-08 11:28:53 / 修改时间：11:32:05" itemprop="dateCreated datePublished" datetime="2020-09-08T11:28:53+08:00">2020-09-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">中间件</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/" itemprop="url" rel="index"><span itemprop="name">redis</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Redis可以做什么"><a href="#Redis可以做什么" class="headerlink" title="Redis可以做什么"></a>Redis可以做什么</h3><p>正常大家知道的就是缓存，又或者分布式情况的分布式锁，还有么？</p>
<p>博客场景会用到redis：</p>
<ol>
<li>记录帖子的点赞数、评论数和点击数 (hash)。</li>
<li>记录用户的帖子 ID 列表 (排序)，便于快速显示用户的帖子列表 (zset)。</li>
<li>记录帖子的标题、摘要、作者和封面信息，用于列表页展示 (hash)。</li>
<li>记录帖子的点赞用户 ID 列表，评论 ID 列表，用于显示和去重计数 (zset)。</li>
<li>缓存近期热帖内容 (帖子内容空间占用比较大)，减少数据库压力 (hash)。</li>
<li>记录帖子的相关文章 ID，根据内容推荐相关帖子 (list)。</li>
<li>如果帖子 ID 是整数自增的，可以使用 Redis 来分配帖子 ID(计数器)。</li>
<li>收藏集和帖子之间的关系 (zset)。</li>
<li>记录热榜帖子 ID 列表，总热榜和分类热榜 (zset)。</li>
<li>缓存用户行为历史，进行恶意行为过滤 (zset,hash)。</li>
<li>数据推送去重Bloom filter</li>
<li>pv，uv统计</li>
</ol>
<p>大家是不是从未发现Redis居然有这么多的用法？</p>
<h3 id="Redis端口为啥是6379"><a href="#Redis端口为啥是6379" class="headerlink" title="Redis端口为啥是6379"></a>Redis端口为啥是6379</h3><p>Redis 由意大利人 Salvatore Sanfilippo（网名 Antirez） 开发，Antirez 不仅帅的不像实力派，也非常有趣。</p>
<p>他出生在非英语系国家，英语能力长期以来是一个短板，他曾经专门为自己蹩脚的英语能力写过一篇博文《英语伤痛 15 年》，用自己的成长经历来鼓励那些非英语系的技术开发者们努力攻克英语难关。</p>
<p>我们都知道 Redis 的默认端口是 6379，这个端口号也不是随机选的，而是由手机键盘字母「MERZ」的位置决定的。</p>
<h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><p>分布式锁本质上要实现的目标就是在 Redis 里面占一个“茅坑”，当别的进程也要来占时，发现已经有人蹲在那里了，就只好放弃或者稍后再试。</p>
<p>占坑一般是使用 setnx(set if not exists) 指令，只允许被一个客户端占坑，先来先占， 用完了，再调用 del 指令释放茅坑。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">setnx aobing</span><br><span class="line">expire aobing</span><br><span class="line">del aobing</span><br></pre></td></tr></table></figure>

<p>失败，怎么办？</p>
<p>当时出现了贼多的第三方插件，作者为了解决这个乱象，就在Redis 2.8 版本中作者加入了 set 指令的扩展参数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set  aobing ture  ex 5 nx</span><br><span class="line">del  aobing</span><br></pre></td></tr></table></figure>

<p>但是这样还是有问题超时问题，可重入问题等等，这个时候，第三方的一些插件就横空出世了，Redission ，Jedis，他们的底层我就不过多描述了，都是通过lua脚本去保证的，大致逻辑跟我们代码实现是差不多的。</p>
<p>就比如去删除的时候，去校验是否当前线程锁定的，就把比较和删除这样一些动作都放到一起了：</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># delifequals</span><br><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&quot;get&quot;</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">&quot;del&quot;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>

<h3 id="延时队列"><a href="#延时队列" class="headerlink" title="延时队列"></a>延时队列</h3><p>我们平时习惯于使用 Rabbitmq 、RocketMQ和 Kafka 作为消息队列中间件，来给应用程序之间增加异步消息传递功能。这两个中间件都是专业的消息队列中间件，特性之多超出了大多数人的理解能力。</p>
<p>使用过 Rabbitmq 的同学知道它使用起来有多复杂，发消息之前要创建 Exchange，再创建 Queue，还要将 Queue 和 Exchange 通过某种规则绑定起来，发消息的时候要指定 routing-key，还要控制头部信息。消费者在消费消息之前也要进行上面一系列的繁琐过程。</p>
<p>但是绝大多数情况下，虽然我们的消息队列只有一组消费者，但还是需要经历上面这些繁琐的过程。</p>
<p>有了 Redis，它就可以让我们解脱出来，对于那些只有一组消费者的消息队列，使用 Redis 就可以非常轻松的搞定。</p>
<p>Redis 的消息队列不是专业的消息队列，它没有非常多的高级特性，没有 ack 保证，如果对消息的可靠性有着极致的追求，那么它就不适合使用。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt; rpush notify-queue apple banana pear</span><br><span class="line">(integer) 3</span><br><span class="line">&gt; llen notify-queue</span><br><span class="line">(integer) 3</span><br><span class="line">&gt; lpop notify-queue</span><br><span class="line">&quot;apple&quot;</span><br><span class="line">&gt; llen notify-queue</span><br><span class="line">(integer) 2</span><br><span class="line">&gt; lpop notify-queue</span><br><span class="line">&quot;banana&quot;</span><br><span class="line">&gt; llen notify-queue</span><br><span class="line">(integer) 1</span><br><span class="line">&gt; lpop notify-queue</span><br><span class="line">&quot;pear&quot;</span><br><span class="line">&gt; llen notify-queue</span><br><span class="line">(integer) 0</span><br><span class="line">&gt; lpop notify-queue</span><br><span class="line">(nil)</span><br></pre></td></tr></table></figure>

<p>但是这样有问题大家发现没有？队列会空是吧，那怎么解决呢？</p>
<p>客户端是通过队列的 pop 操作来获取消息，然后进行处理，处理完了再接着获取消息，再进行处理。</p>
<p>如此循环往复，这便是作为队列消费者的客户端的生命周期。</p>
<p>可是如果队列空了，客户端就会陷入 pop 的死循环，不停地 pop，没有数据，接着再 pop，又没有数据，这就是浪费生命的空轮询。</p>
<p>空轮询不但拉高了客户端的 CPU，redis 的 QPS 也会被拉高，如果这样空轮询的客户端有几十来个，Redis 的慢查询可能会显著增多。</p>
<p>解决方式很简单，让线程睡一秒 Thread.sleep(1000)</p>
<p>Redis在我开发的一些简易后台我确实有用到，因为我觉得没必要接入消息队列中间件，大家平时开发小系统可以试试。</p>
<h3 id="位图bitmap"><a href="#位图bitmap" class="headerlink" title="位图bitmap"></a>位图bitmap</h3><p>在我们平时开发过程中，会有一些 bool 型数据需要存取，比如用户一年的签到记录，签了是 1，没签是 0，要记录 365 天。如果使用普通的 key/value，每个用户要记录 365 个，当用户上亿的时候，需要的存储空间是惊人的。</p>
<p>为了解决这个问题，Redis 提供了位图数据结构，这样每天的签到记录只占据一个位，365 天就是 365 个位，46 个字节 (一个稍长一点的字符串) 就可以完全容纳下，这就大大节约了存储空间。</p>
<p>位图不是特殊的数据结构，它的内容其实就是普通的字符串，也就是 byte 数组。我们可以使用普通的 get/set 直接获取和设置整个位图的内容，也可以使用位图操作 getbit/setbit 等将 byte 数组看成「位数组」来处理。</p>
<p>当我们要统计月活的时候，因为需要去重，需要使用 set 来记录所有活跃用户的 id，这非常浪费内存。</p>
<p>这时就可以考虑使用位图来标记用户的活跃状态。每个用户会都在这个位图的一个确定位置上，0 表示不活跃，1 表示活跃。然后到月底遍历一次位图就可以得到月度活跃用户数。</p>
<p>这个类型不仅仅可以用来让我们改二进制改字符串值，最经典的就是用户连续签到。</p>
<p>key 可以设置为 前缀:用户id:年月    譬如 setbit sign:123:1909 0 1</p>
<p>代表用户ID=123签到，签到的时间是19年9月份，0代表该月第一天，1代表签到了</p>
<p>第二天没有签到，无需处理，系统默认为0</p>
<p>第三天签到  setbit sign:123:1909 2 1</p>
<p>可以查看一下目前的签到情况，显示第一天和第三天签到了，前8天目前共签到了2天</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; setbit sign:123:1909 0 1</span><br><span class="line">0</span><br><span class="line">127.0.0.1:6379&gt; setbit sign:123:1909 2 1</span><br><span class="line">0</span><br><span class="line">127.0.0.1:6379&gt; getbit sign:123:1909 0</span><br><span class="line">1</span><br><span class="line">127.0.0.1:6379&gt; getbit sign:123:1909 1</span><br><span class="line">0</span><br><span class="line">127.0.0.1:6379&gt; getbit sign:123:1909 2</span><br><span class="line">1</span><br><span class="line">127.0.0.1:6379&gt; getbit sign:123:1909 3</span><br><span class="line">0</span><br><span class="line">127.0.0.1:6379&gt; bitcount sign:123:1909 0 0</span><br><span class="line">2</span><br></pre></td></tr></table></figure>

<h3 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h3><p>如果统计 PV 那非常好办，给每个网页一个独立的 Redis 计数器就可以了，这个计数器的 key 后缀加上当天的日期。这样来一个请求，incrby 一次，最终就可以统计出所有的 PV 数据。</p>
<p>但是 UV 不一样，它要去重，同一个用户一天之内的多次访问请求只能计数一次。</p>
<p>这就要求每一个网页请求都需要带上用户的 ID，无论是登陆用户还是未登陆用户都需要一个唯一 ID 来标识。</p>
<p>你也许已经想到了一个简单的方案，那就是为每一个页面一个独立的 set 集合来存储所有当天访问过此页面的用户 ID。</p>
<p>当一个请求过来时，我们使用 sadd 将用户 ID 塞进去就可以了。</p>
<p>通过 scard 可以取出这个集合的大小，这个数字就是这个页面的 UV 数据。没错，这是一个非常简单的方案。</p>
<p>但是，如果你的页面访问量非常大，比如一个爆款页面几千万的 UV，你需要一个很大的 set 集合来统计，这就非常浪费空间。</p>
<p>如果这样的页面很多，那所需要的存储空间是惊人的。为这样一个去重功能就耗费这样多的存储空间，值得么？其实老板需要的数据又不需要太精确，105w 和 106w 这两个数字对于老板们来说并没有多大区别，So，有没有更好的解决方案呢？</p>
<p>HyperLogLog 提供了两个指令 pfadd 和 pfcount，根据字面意义很好理解，一个是增加计数，一个是获取计数。</p>
<p>pfadd 用法和 set 集合的 sadd 是一样的，来一个用户 ID，就将用户 ID 塞进去就是，pfcount 和 scard 用法是一样的，直接获取计数值。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; pfadd codehole user1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount codehole</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfadd codehole user2</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount codehole</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; pfadd codehole user3</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount codehole</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; pfadd codehole user4</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount codehole</span><br><span class="line">(integer) 4</span><br><span class="line">127.0.0.1:6379&gt; pfadd codehole user5</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount codehole</span><br><span class="line">(integer) 5</span><br><span class="line">127.0.0.1:6379&gt; pfadd codehole user6</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount codehole</span><br><span class="line">(integer) 6</span><br><span class="line">127.0.0.1:6379&gt; pfadd codehole user7 user8 user9 user10</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount codehole</span><br><span class="line">(integer) 10</span><br></pre></td></tr></table></figure>

<h3 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h3><p>HyperLogLog 数据结构来进行估数，它非常有价值，可以解决很多精确度不高的统计需求。</p>
<p>但是如果我们想知道某一个值是不是已经在 HyperLogLog 结构里面了，它就无能为力了，它只提供了 pfadd 和 pfcount 方法，没有提供 pfcontains 这种方法。</p>
<p>讲个使用场景，比如我们在使用新闻客户端看新闻时，它会给我们不停地推荐新的内容，它每次推荐时要去重，去掉那些已经看过的内容。问题来了，新闻客户端推荐系统如何实现推送去重的？</p>
<p>你会想到服务器记录了用户看过的所有历史记录，当推荐系统推荐新闻时会从每个用户的历史记录里进行筛选，过滤掉那些已经存在的记录。问题是当用户量很大，每个用户看过的新闻又很多的情况下，这种方式，推荐系统的去重工作在性能上跟的上么？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; bf.add codehole user1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bf.add codehole user2</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bf.add codehole user3</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bf.exists codehole user1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bf.exists codehole user2</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bf.exists codehole user3</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bf.exists codehole user4</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; bf.madd codehole user4 user5 user6</span><br><span class="line">1) (integer) 1</span><br><span class="line">2) (integer) 1</span><br><span class="line">3) (integer) 1</span><br><span class="line">127.0.0.1:6379&gt; bf.mexists codehole user4 user5 user6 user7</span><br><span class="line">1) (integer) 1</span><br><span class="line">2) (integer) 1</span><br><span class="line">3) (integer) 1</span><br><span class="line">4) (integer) 0</span><br></pre></td></tr></table></figure>

<p>布隆过滤器的initial_size估计的过大，会浪费存储空间，估计的过小，就会影响准确率，用户在使用之前一定要尽可能地精确估计好元素数量，还需要加上一定的冗余空间以避免实际元素可能会意外高出估计值很多。</p>
<p>布隆过滤器的error_rate越小，需要的存储空间就越大，对于不需要过于精确的场合，error_rate设置稍大一点也无伤大雅。比如在新闻去重上而言，误判率高一点只会让小部分文章不能让合适的人看到，文章的整体阅读量不会因为这点误判率就带来巨大的改变。</p>
<p>在爬虫系统中，我们需要对 URL 进行去重，已经爬过的网页就可以不用爬了。但是 URL 太多了，几千万几个亿，如果用一个集合装下这些 URL 地址那是非常浪费空间的。这时候就可以考虑使用布隆过滤器。它可以大幅降低去重存储消耗，只不过也会使得爬虫系统错过少量的页面。</p>
<p>布隆过滤器在 NoSQL 数据库领域使用非常广泛，我们平时用到的 HBase、Cassandra 还有 LevelDB、RocksDB 内部都有布隆过滤器结构，布隆过滤器可以显著降低数据库的 IO 请求数量。当用户来查询某个 row 时，可以先通过内存中的布隆过滤器过滤掉大量不存在的 row 请求，然后再去磁盘进行查询。</p>
<p>邮箱系统的垃圾邮件过滤功能也普遍用到了布隆过滤器，因为用了这个过滤器，所以平时也会遇到某些正常的邮件被放进了垃圾邮件目录中，这个就是误判所致，概率很低。</p>
<p>他其实还有很多用法，我没怎么讲，比如限流，附近的人GeoHash等等，我们公司的附近的人也是用它实现的。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/HyperLoglog/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/nanchenkunkun.github.io/images/1.jpg">
      <meta itemprop="name" content="zkk">
      <meta itemprop="description" content="只有变光,才能变强">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kkの博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/nanchenkunkun.github.io/2020/09/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/HyperLoglog/" class="post-title-link" itemprop="url">Hyper LogLog</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-09-08 11:28:53 / 修改时间：11:30:58" itemprop="dateCreated datePublished" datetime="2020-09-08T11:28:53+08:00">2020-09-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">中间件</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/nanchenkunkun.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/" itemprop="url" rel="index"><span itemprop="name">redis</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Hyper-LogLog"><a href="#Hyper-LogLog" class="headerlink" title="Hyper LogLog"></a>Hyper LogLog</h2><p>​        Hyper LogLog 计数器的名称是具有自描述性的。 你可以仅仅使用<code>loglog(Nmax)+ O(1)</code>位来估计基数为 Nmax 的集合的基数。</p>
<h2 id="Redis-Hyperloglog-操作"><a href="#Redis-Hyperloglog-操作" class="headerlink" title="Redis Hyperloglog 操作"></a>Redis Hyperloglog 操作</h2><p>要进行 Redis Hyperloglog 的操作，我们可以使用以下三个命令：</p>
<ul>
<li><code>PFADD</code></li>
<li><code>PFCOUNT</code></li>
<li><code>PFMERGE</code></li>
</ul>
<p>我们用一个实际的例子来解释这些命令。比如，有这么个场景，用户登录到系统，我们需要在一小时内统计不同的用户。 因此，我们需要一个 key，例如 USER:LOGIN:2019092818。 换句话说，我们要统计在 2019 年 09 月 28 日下午 18 点至 19 点之间发生用户登录操作的非重复用户数。对于将来的时间，我们也需要使用对应的 key 进行表示，比如 2019111100、2019111101、2019111102 等。</p>
<p>我们假设，用户 A、B、C、D、E 和 F 在下午 18 点至 19 点之间登录了系统。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; pfadd USER:LOGIN:2019092818 A</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfadd USER:LOGIN:2019092818 B C D E F</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure>

<p>当进行计数时，你会得到预期的 6。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; pfcount USER:LOGIN:2019092818</span><br><span class="line">(integer) 6</span><br></pre></td></tr></table></figure>

<p>如果 A 和 B 在这个时间内多次登录系统，你也将得到相同的结果，因为我们仅保留不同的用户。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; pfadd USER:LOGIN:2019092818 A B</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; pfcount USER:LOGIN:2019092818</span><br><span class="line">(integer) 6</span><br></pre></td></tr></table></figure>

<p>如果用户 A~F 和另外一个其他用户 G 在下午 19 点至下午 20 点之间登录系统：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; pfadd USER:LOGIN:2019092819 A B C D E F G</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; pfcount USER:LOGIN:2019092819</span><br><span class="line">(integer) 7</span><br></pre></td></tr></table></figure>

<p>现在，我们有两个键 USER:LOGIN:2019092818 和 USER:LOGIN:2019092819，如果我们想知道在 18 点到 20 点（2 小时）之间有多少不同的用户登录到系统中，我们可以直接使用<code>pfcount</code>命令对两个键进行合并计数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; pfcount USER:LOGIN:2019092818 USER:LOGIN:2019092819</span><br><span class="line">(integer) 7</span><br></pre></td></tr></table></figure>

<p>如果我们需要保留键值而避免一遍又一遍地计数，那么我们可以将键合并为一个键 USER:LOGIN:2019092818-19，然后直接对该键进行<code>pfcount</code>操作，如下所示。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; pfmerge USER:LOGIN:2019092818-19 USER:LOGIN:2019092818 USER:LOGIN:2019092819</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; pfcount USER:LOGIN:2019092818-19</span><br><span class="line">(integer) 7</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/nanchenkunkun.github.io/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/nanchenkunkun.github.io/page/4/">4</a><a class="extend next" rel="next" href="/nanchenkunkun.github.io/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="zkk"
      src="/nanchenkunkun.github.io/images/1.jpg">
  <p class="site-author-name" itemprop="name">zkk</p>
  <div class="site-description" itemprop="description">只有变光,才能变强</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/nanchenkunkun.github.io/archives/">
        
          <span class="site-state-item-count">33</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/nanchenkunkun.github.io/categories/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/nanchenkunkun.github.io/tags/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zkk</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/nanchenkunkun.github.io/lib/anime.min.js"></script>
  <script src="/nanchenkunkun.github.io/lib/velocity/velocity.min.js"></script>
  <script src="/nanchenkunkun.github.io/lib/velocity/velocity.ui.min.js"></script>

<script src="/nanchenkunkun.github.io/js/utils.js"></script>

<script src="/nanchenkunkun.github.io/js/motion.js"></script>


<script src="/nanchenkunkun.github.io/js/schemes/pisces.js"></script>


<script src="/nanchenkunkun.github.io/js/next-boot.js"></script>




  















  

  

</body>
</html>
